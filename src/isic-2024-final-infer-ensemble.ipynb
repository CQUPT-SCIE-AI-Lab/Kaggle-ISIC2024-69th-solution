{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":63056,"databundleVersionId":9094797,"sourceType":"competition"},{"sourceId":9259236,"sourceType":"datasetVersion","datasetId":5602402},{"sourceId":9265228,"sourceType":"datasetVersion","datasetId":5606682},{"sourceId":9273501,"sourceType":"datasetVersion","datasetId":5612311},{"sourceId":9273517,"sourceType":"datasetVersion","datasetId":5612326},{"sourceId":9273532,"sourceType":"datasetVersion","datasetId":5612338},{"sourceId":9325151,"sourceType":"datasetVersion","datasetId":5649297}],"dockerImageVersionId":30762,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# DL Part","metadata":{}},{"cell_type":"markdown","source":"## Import Libs","metadata":{}},{"cell_type":"code","source":"import os\nimport random\nimport gc\nimport time\nimport copy\nimport sys\nimport numpy as np\nimport pandas as pd\nimport h5py\nfrom io import BytesIO\n\nfrom torch.utils.data import Dataset, DataLoader\nimport torch\nimport torch.nn.functional as F\nfrom torch import nn\nimport timm\n\nfrom PIL import Image\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom tqdm import tqdm\nfrom collections import defaultdict\n\nimport warnings # 避免一些可以忽略的报错\nwarnings.filterwarnings('ignore')\n# For colored terminal text\nfrom colorama import Fore, Back, Style\nb_ = Fore.BLUE\nsr_ = Style.RESET_ALL","metadata":{"execution":{"iopub.status.busy":"2024-09-05T11:01:41.795328Z","iopub.execute_input":"2024-09-05T11:01:41.795716Z","iopub.status.idle":"2024-09-05T11:02:09.486064Z","shell.execute_reply.started":"2024-09-05T11:01:41.795677Z","shell.execute_reply":"2024-09-05T11:02:09.485176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## CONFIG","metadata":{}},{"cell_type":"code","source":"is_debug = False\n\nclass CONFIG:\n    seed = 308\n    n_seed = [7, 42, 308, 666, 7777, 9216]\n    # 256 tiny_vit ---------- 3h+\n    # 512 efficientnet convnext -------------- 17mins+\n    #     efficientvit_b0 --------------- 7mins+\n    test_batch_size = 512\n    img_size = [160, 160]\n    n_classes = 1\n    n_folds = 5\n    \n    n_accumulate = 1.0\n    n_workers = os.cpu_count()\n\n    DataParallel = False\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n    \"\"\"\n    tf_efficientnet_b0_ns\n    tiny_vit_21m_512.dist_in22k_ft_in1k\n    eva02_base_patch14_224.mim_in22k\n    convnext_tiny.fb_in22k_ft_in1k_384\n    tf_efficientnetv2_s.in21k_ft_in1k\n    efficientvit_b0.r224_in1k\n    \n    edgenext_base.in21k_ft_in1k\n    \"\"\"\n    model_name = \"ensemble_linear\"\n    model_names = [\"tf_efficientnetv2_s.in21k_ft_in1k\",\n                   \"edgenext_base.in21k_ft_in1k\",\n                   \"convnext_atto_ols.a2_in1k\",\n                   \"tf_efficientnet_b3.ns_jft_in1k\"]\n    ensemble_path = \"/kaggle/input/20240829-ensemblel-train1954-cv159\"\n    ckpt_path = [\"/kaggle/input/20240827-efficientnetv2s-train1954-cv15496\",\n                 \"/kaggle/input/20240828-edgenext-train1954-cv0-1519\",\n                 \"/kaggle/input/20240829-convnext-atto-train1954-cv149\",\n                 \"/kaggle/input/20240829-efficientnet-b3-train1954-cv1504\"]\n    use_gempool = False\n    dl_pred_name = \"cv159\"\n    GBDT_ckpt_paths = \"/kaggle/input/20240905-gbdt-6seed-cv181877\"\n    \n    test_csv = \"/kaggle/input/isic-2024-challenge/test-metadata.csv\"\n    test_img_hdf5 = \"/kaggle/input/isic-2024-challenge/test-image.hdf5\"\n    \n#     # debug\n#     test_csv = \"/kaggle/input/isic-2024-challenge/train-metadata.csv\"\n#     test_img_hdf5 = \"/kaggle/input/isic-2024-challenge/train-image.hdf5\"\n    \n    my_train_csv = \"/kaggle/input/isic2024-my-train-csv/my_train.csv\"\n\nif CONFIG.DataParallel:\n    os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'\n    print(\"IN DataParallel!\")\nelse:\n    os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n    print(\"NO IN DataParallel!\")","metadata":{"execution":{"iopub.status.busy":"2024-09-05T11:02:09.487907Z","iopub.execute_input":"2024-09-05T11:02:09.488460Z","iopub.status.idle":"2024-09-05T11:02:09.521422Z","shell.execute_reply.started":"2024-09-05T11:02:09.488424Z","shell.execute_reply":"2024-09-05T11:02:09.520440Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Set Random Seed","metadata":{}},{"cell_type":"code","source":"def set_seed(seed=308):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\nset_seed(CONFIG.seed)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T11:02:09.522752Z","iopub.execute_input":"2024-09-05T11:02:09.523173Z","iopub.status.idle":"2024-09-05T11:02:09.539856Z","shell.execute_reply.started":"2024-09-05T11:02:09.523109Z","shell.execute_reply":"2024-09-05T11:02:09.538873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Progress","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv(CONFIG.test_csv)\ntest","metadata":{"execution":{"iopub.status.busy":"2024-09-05T11:02:09.542472Z","iopub.execute_input":"2024-09-05T11:02:09.542890Z","iopub.status.idle":"2024-09-05T11:02:09.595933Z","shell.execute_reply.started":"2024-09-05T11:02:09.542847Z","shell.execute_reply":"2024-09-05T11:02:09.594988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset and DataLoader","metadata":{}},{"cell_type":"code","source":"def transform(img):\n    composition = A.Compose([\n        A.Resize(CONFIG.img_size[0], CONFIG.img_size[1]),\n        A.Normalize(),\n        ToTensorV2(),\n    ])\n    return composition(image=img)[\"image\"]","metadata":{"execution":{"iopub.status.busy":"2024-09-05T11:02:09.597066Z","iopub.execute_input":"2024-09-05T11:02:09.597392Z","iopub.status.idle":"2024-09-05T11:02:09.602950Z","shell.execute_reply.started":"2024-09-05T11:02:09.597359Z","shell.execute_reply":"2024-09-05T11:02:09.601970Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MyDataset(Dataset):\n    def __init__(self, df, img_hdf5, transform=None):\n        super().__init__()\n        self.df = df\n        self.fp_hdf = h5py.File(img_hdf5, mode=\"r\")\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx, :]\n        img_id = row.isic_id\n        label = str(img_id)\n        \n        img = np.array( Image.open(BytesIO(self.fp_hdf[img_id][()])) )\n        img = np.array(img).astype(np.float32)\n\n        if self.transform != None:\n            img = self.transform(img)\n\n        return img, label","metadata":{"execution":{"iopub.status.busy":"2024-09-05T11:02:09.604236Z","iopub.execute_input":"2024-09-05T11:02:09.604555Z","iopub.status.idle":"2024-09-05T11:02:09.613839Z","shell.execute_reply.started":"2024-09-05T11:02:09.604509Z","shell.execute_reply":"2024-09-05T11:02:09.612986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_loaders(df):\n\n    test_datasets = MyDataset(df=df, img_hdf5=CONFIG.test_img_hdf5, transform=transform)\n    \n    test_loader = DataLoader(test_datasets, batch_size=CONFIG.test_batch_size, num_workers=CONFIG.n_workers, shuffle=False, pin_memory=True)\n    \n    return test_loader","metadata":{"execution":{"iopub.status.busy":"2024-09-05T11:02:09.614954Z","iopub.execute_input":"2024-09-05T11:02:09.615278Z","iopub.status.idle":"2024-09-05T11:02:09.622613Z","shell.execute_reply.started":"2024-09-05T11:02:09.615245Z","shell.execute_reply":"2024-09-05T11:02:09.621664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_loader = prepare_loaders(test)\n# x, y = next(iter(test_loader))\n# x.shape","metadata":{"execution":{"iopub.status.busy":"2024-09-05T11:02:09.623956Z","iopub.execute_input":"2024-09-05T11:02:09.624640Z","iopub.status.idle":"2024-09-05T11:02:09.635523Z","shell.execute_reply.started":"2024-09-05T11:02:09.624604Z","shell.execute_reply":"2024-09-05T11:02:09.634467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## DL Model","metadata":{}},{"cell_type":"code","source":"def updata_req_grad(models, requires_grad=True):\n    for model in models:\n        for param in model.parameters():\n            param.requires_grad = requires_grad","metadata":{"execution":{"iopub.status.busy":"2024-09-05T11:02:09.636853Z","iopub.execute_input":"2024-09-05T11:02:09.637291Z","iopub.status.idle":"2024-09-05T11:02:09.645898Z","shell.execute_reply.started":"2024-09-05T11:02:09.637247Z","shell.execute_reply":"2024-09-05T11:02:09.644948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class GeMPool(nn.Module):\n    def __init__(self, p=3, eps=1e-6):\n        super(GeMPool, self).__init__()\n        self.p = nn.Parameter(torch.ones(1) * p)\n        self.eps = eps\n\n    def forward(self, x):\n        return self.gem(x, p=self.p, eps=self.eps)\n    \n    def gem(self, x, p=3, eps=1e-6):\n        return torch.mean(x.clamp(min=eps).pow(p), dim=(-2, -1)).pow(1./p)\n    \n    def __repr__(self):\n        return self.__class__.__name__ + f'(p={self.p.data.tolist()[0]:.4f}, eps={self.eps})'","metadata":{"execution":{"iopub.status.busy":"2024-09-05T11:02:09.650644Z","iopub.execute_input":"2024-09-05T11:02:09.651058Z","iopub.status.idle":"2024-09-05T11:02:09.659058Z","shell.execute_reply.started":"2024-09-05T11:02:09.651020Z","shell.execute_reply":"2024-09-05T11:02:09.658074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ensemblelinear(nn.Module):\n    def __init__(self, in_features, out_features=1) -> None:\n        super().__init__()\n        self.model = nn.Linear(in_features, in_features, bias=False)\n        self.softmax = nn.Softmax()\n        self.out_features = out_features\n\n    def forward(self, x):\n        Identity = x\n        # print(f\"Identity: {Identity}\")\n        _tmp = self.model(x)\n        _tmp = self.softmax(_tmp)\n        _tmp = Identity * _tmp\n        output = _tmp.sum(1).reshape(-1, self.out_features)\n        # print(f\"output: {output}\")\n        return output","metadata":{"execution":{"iopub.status.busy":"2024-09-05T11:02:09.660501Z","iopub.execute_input":"2024-09-05T11:02:09.660807Z","iopub.status.idle":"2024-09-05T11:02:09.671937Z","shell.execute_reply.started":"2024-09-05T11:02:09.660775Z","shell.execute_reply":"2024-09-05T11:02:09.670969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ISIC2024Model(nn.Module):\n    def __init__(self, model_name=CONFIG.model_names[0]):\n        super(ISIC2024Model, self).__init__()\n        self.backbone = timm.create_model(model_name=model_name, \n                                          pretrained=False)\n        \n        if \"efficientnet\" in model_name:\n            in_features = self.backbone.classifier.in_features\n            self.backbone.classifier = nn.Identity()\n            if CONFIG.use_gempool:\n                self.backbone.global_pool = GeMPool()\n        elif \"convnext\" in model_name or \"tiny_vit\" in model_name:\n            in_features = self.backbone.head.fc.in_features\n            self.backbone.head.fc = nn.Identity()\n        elif \"eva\" in model_name:\n            in_features = 768\n        elif \"efficientvit\" in model_name:\n            in_features = self.backbone.head.classifier[4].in_features\n            self.backbone.head.classifier[4] = nn.Identity()\n        elif \"edgenext\" in model_name:\n            in_features = self.backbone.head.fc.in_features\n            self.backbone.head.fc = nn.Identity()\n\n        self.head = nn.Sequential(\n            nn.Linear(in_features, CONFIG.n_classes)\n        )\n        \n    def forward(self, x):\n        _tmp = self.backbone(x)\n        output = self.head(_tmp)\n        return output","metadata":{"execution":{"iopub.status.busy":"2024-09-05T11:02:09.673126Z","iopub.execute_input":"2024-09-05T11:02:09.673461Z","iopub.status.idle":"2024-09-05T11:02:09.683412Z","shell.execute_reply.started":"2024-09-05T11:02:09.673429Z","shell.execute_reply":"2024-09-05T11:02:09.682579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Models","metadata":{}},{"cell_type":"code","source":"from collections import OrderedDict\n\ndef remove_module(path):\n    # 加载保存的状态字典\n    state_dict = torch.load(path)\n\n    # 使用 OrderedDict 去掉 'module.' 前缀\n    new_state_dict = OrderedDict()\n    for key, value in state_dict.items():\n        new_state_dict[key.replace('module.', '')] = value\n    return new_state_dict","metadata":{"execution":{"iopub.status.busy":"2024-09-05T11:02:09.684392Z","iopub.execute_input":"2024-09-05T11:02:09.684676Z","iopub.status.idle":"2024-09-05T11:02:09.695744Z","shell.execute_reply.started":"2024-09-05T11:02:09.684645Z","shell.execute_reply":"2024-09-05T11:02:09.695020Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load DL Models\nmore_models = []\n\nfor n_models in range(len(CONFIG.model_names)):\n    models = []\n    all_paths = sorted(os.listdir(CONFIG.ckpt_path[n_models]))\n    paths = []\n    for i in range(CONFIG.n_folds):\n        _tmp_paths = []\n        for path in all_paths:\n            if path[0] == str(i+1):\n                _tmp_paths.append(path)\n        paths.append(_tmp_paths[-1])\n    # paths = [\"1_CV0.1547_Loss0.6784_epoch2.bin\",\n    #          \"2_CV0.1708_Loss0.5088_epoch5.bin\",\n    #          \"3_CV0.1791_Loss0.3739_epoch7.bin\",\n    #          \"4_CV0.1654_Loss0.5382_epoch3.bin\",\n    #          \"5_CV0.1812_Loss0.4236_epoch8.bin\"]\n\n    if CONFIG.DataParallel:\n        device_ids = [0, 1]\n        for i in range(CONFIG.n_folds):\n            model = ISIC2024Model(model_name=CONFIG.model_names[n_models])\n            model = torch.nn.DataParallel(model, device_ids=device_ids)\n            model = model.cuda()\n            model.load_state_dict(torch.load(os.path.join(CONFIG.ckpt_path[n_models], paths[i])))\n            print(f\"fold : {i} --------- path : {paths[i]}\")\n            model.eval()\n            models.append(model)\n    else:\n        for i in range(CONFIG.n_folds):\n            model = ISIC2024Model(model_name=CONFIG.model_names[n_models])\n            model = model.cuda()\n            model.load_state_dict(remove_module(os.path.join(CONFIG.ckpt_path[n_models], paths[i])))\n            print(f\"fold : {i} --------- path : {paths[i]}\")\n            model.eval()\n            models.append(model)\n    more_models.append(models)\n    print(f\"{CONFIG.model_names[n_models]} load success.\")","metadata":{"execution":{"iopub.status.busy":"2024-09-05T11:02:09.696943Z","iopub.execute_input":"2024-09-05T11:02:09.697331Z","iopub.status.idle":"2024-09-05T11:02:31.336565Z","shell.execute_reply.started":"2024-09-05T11:02:09.697273Z","shell.execute_reply":"2024-09-05T11:02:31.335586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load ensemble Models\nensemble_models = []\n\npaths = sorted(os.listdir(CONFIG.ensemble_path))\n\nif CONFIG.DataParallel:\n    device_ids = [0, 1]\n    for i in range(CONFIG.n_folds):\n        model = ensemblelinear(in_features=len(CONFIG.model_names))\n        model = torch.nn.DataParallel(model, device_ids=device_ids)\n        model = model.cuda()\n        model.load_state_dict(torch.load(os.path.join(CONFIG.ensemble_path, paths[i])))\n        print(f\"fold : {i} --------- path : {paths[i]}\")\n        model.eval()\n        ensemble_models.append(model)\nelse:\n    for i in range(CONFIG.n_folds):\n        model = ensemblelinear(in_features=len(CONFIG.model_names))\n        model = model.cuda()\n        model.load_state_dict(remove_module(os.path.join(CONFIG.ensemble_path, paths[i])))\n        print(f\"fold : {i} --------- path : {paths[i]}\")\n        model.eval()\n        ensemble_models.append(model)\nprint(f\"{CONFIG.model_name} load success.\")","metadata":{"execution":{"iopub.status.busy":"2024-09-05T11:02:31.337729Z","iopub.execute_input":"2024-09-05T11:02:31.338015Z","iopub.status.idle":"2024-09-05T11:02:31.390826Z","shell.execute_reply.started":"2024-09-05T11:02:31.337985Z","shell.execute_reply":"2024-09-05T11:02:31.389835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Infer Function","metadata":{}},{"cell_type":"code","source":"def Infer(ensemble_model, dl_models, test_loader):\n    y_preds = []\n    bar = tqdm(enumerate(test_loader), total=len(test_loader))\n    with torch.no_grad():\n        for step, (images, study_id) in bar:\n            \n            if CONFIG.DataParallel:\n                images = images.cuda().float()\n            else:\n                images = images.to(CONFIG.device, dtype=torch.float)\n                \n            ensemble_input = []\n            for dl_model in dl_models:\n                output = dl_model(images)\n                output = F.sigmoid(output)\n                ensemble_input.append(output)\n            ensemble_input = torch.cat(ensemble_input, axis=1)\n            outputs = ensemble_model(ensemble_input)\n            y_preds.append(outputs.detach().flatten().cpu().numpy())\n            \n    y_preds = np.concatenate(y_preds)\n    return y_preds","metadata":{"execution":{"iopub.status.busy":"2024-09-05T11:02:31.392325Z","iopub.execute_input":"2024-09-05T11:02:31.393040Z","iopub.status.idle":"2024-09-05T11:02:31.400858Z","shell.execute_reply.started":"2024-09-05T11:02:31.392987Z","shell.execute_reply":"2024-09-05T11:02:31.399924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Start Infer","metadata":{}},{"cell_type":"code","source":"# test preds\ntotal_test_pred = []\n\nfor fold in range(CONFIG.n_folds):\n    test_loader = prepare_loaders(test)\n    dl_model = []\n    for dl_model_per in more_models:\n        dl_model.append(dl_model_per[fold])\n    preds = Infer(ensemble_models[fold], dl_model, test_loader)\n    total_test_pred.append(preds)\n    \ntotal_test_pred = np.mean(total_test_pred, axis=0)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T11:02:31.402197Z","iopub.execute_input":"2024-09-05T11:02:31.402577Z","iopub.status.idle":"2024-09-05T11:02:33.980049Z","shell.execute_reply.started":"2024-09-05T11:02:31.402529Z","shell.execute_reply":"2024-09-05T11:02:33.979049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ML Part","metadata":{}},{"cell_type":"markdown","source":"## Import libs","metadata":{}},{"cell_type":"code","source":"import os\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nimport polars as pl\nfrom joblib import load\n\nfrom sklearn.model_selection import StratifiedGroupKFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.ensemble import VotingClassifier\n\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.pipeline import Pipeline\n\nimport lightgbm as lgb\nimport catboost as cb\nimport xgboost as xgb\n\nimport optuna\nfrom tqdm import tqdm\nimport gc\nimport warnings # 避免一些可以忽略的报错\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2024-09-05T11:02:33.981916Z","iopub.execute_input":"2024-09-05T11:02:33.982464Z","iopub.status.idle":"2024-09-05T11:02:38.654114Z","shell.execute_reply.started":"2024-09-05T11:02:33.982413Z","shell.execute_reply":"2024-09-05T11:02:38.653265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## CONFIG","metadata":{}},{"cell_type":"code","source":"root = Path('/kaggle/input/isic-2024-challenge')\n\ntrain_path = root / 'train-metadata.csv'\n# /kaggle/input/isic2024-my-train-csv/my_train.csv\ntest_path = root / 'test-metadata.csv'\nsubm_path = root / 'sample_submission.csv'\nGBDT_ckpt_paths = CONFIG.GBDT_ckpt_paths\n\nid_col = 'isic_id'\ntarget_col = 'target'\ngroup_col = 'patient_id'\n\nerr = 1e-5\nsampling_ratio = 0.01\nseed = 308\n\nnum_cols = [\n    'age_approx',                        # Approximate age of patient at time of imaging.\n    'clin_size_long_diam_mm',            # Maximum diameter of the lesion (mm).+\n    'tbp_lv_A',                          # A inside  lesion.+\n    'tbp_lv_Aext',                       # A outside lesion.+\n    'tbp_lv_B',                          # B inside  lesion.+\n    'tbp_lv_Bext',                       # B outside lesion.+ \n    'tbp_lv_C',                          # Chroma inside  lesion.+\n    'tbp_lv_Cext',                       # Chroma outside lesion.+\n    'tbp_lv_H',                          # Hue inside the lesion; calculated as the angle of A* and B* in LAB* color space. Typical values range from 25 (red) to 75 (brown).+\n    'tbp_lv_Hext',                       # Hue outside lesion.+\n    'tbp_lv_L',                          # L inside lesion.+\n    'tbp_lv_Lext',                       # L outside lesion.+\n    'tbp_lv_areaMM2',                    # Area of lesion (mm^2).+\n    'tbp_lv_area_perim_ratio',           # Border jaggedness, the ratio between lesions perimeter and area. Circular lesions will have low values; irregular shaped lesions will have higher values. Values range 0-10.+\n    'tbp_lv_color_std_mean',             # Color irregularity, calculated as the variance of colors within the lesion's boundary.\n    'tbp_lv_deltaA',                     # Average A contrast (inside vs. outside lesion).+\n    'tbp_lv_deltaB',                     # Average B contrast (inside vs. outside lesion).+\n    'tbp_lv_deltaL',                     # Average L contrast (inside vs. outside lesion).+\n    'tbp_lv_deltaLB',                    #\n    'tbp_lv_deltaLBnorm',                # Contrast between the lesion and its immediate surrounding skin. Low contrast lesions tend to be faintly visible such as freckles; high contrast lesions tend to be those with darker pigment. Calculated as the average delta LB of the lesion relative to its immediate background in LAB* color space. Typical values range from 5.5 to 25.+\n    'tbp_lv_eccentricity',               # Eccentricity.+\n    'tbp_lv_minorAxisMM',                # Smallest lesion diameter (mm).+\n    'tbp_lv_nevi_confidence',            # Nevus confidence score (0-100 scale) is a convolutional neural network classifier estimated probability that the lesion is a nevus. The neural network was trained on approximately 57,000 lesions that were classified and labeled by a dermatologist.+,++\n    'tbp_lv_norm_border',                # Border irregularity (0-10 scale); the normalized average of border jaggedness and asymmetry.+\n    'tbp_lv_norm_color',                 # Color variation (0-10 scale); the normalized average of color asymmetry and color irregularity.+\n    'tbp_lv_perimeterMM',                # Perimeter of lesion (mm).+\n    'tbp_lv_radial_color_std_max',       # Color asymmetry, a measure of asymmetry of the spatial distribution of color within the lesion. This score is calculated by looking at the average standard deviation in LAB* color space within concentric rings originating from the lesion center. Values range 0-10.+\n    'tbp_lv_stdL',                       # Standard deviation of L inside  lesion.+\n    'tbp_lv_stdLExt',                    # Standard deviation of L outside lesion.+\n    'tbp_lv_symm_2axis',                 # Border asymmetry; a measure of asymmetry of the lesion's contour about an axis perpendicular to the lesion's most symmetric axis. Lesions with two axes of symmetry will therefore have low scores (more symmetric), while lesions with only one or zero axes of symmetry will have higher scores (less symmetric). This score is calculated by comparing opposite halves of the lesion contour over many degrees of rotation. The angle where the halves are most similar identifies the principal axis of symmetry, while the second axis of symmetry is perpendicular to the principal axis. Border asymmetry is reported as the asymmetry value about this second axis. Values range 0-10.+\n    'tbp_lv_symm_2axis_angle',           # Lesion border asymmetry angle.+\n    'tbp_lv_x',                          # X-coordinate of the lesion on 3D TBP.+\n    'tbp_lv_y',                          # Y-coordinate of the lesion on 3D TBP.+\n    'tbp_lv_z',                          # Z-coordinate of the lesion on 3D TBP.+\n]\n\nnew_num_cols = [\n    'lesion_size_ratio',                 # tbp_lv_minorAxisMM      / clin_size_long_diam_mm\n    'lesion_shape_index',                # tbp_lv_areaMM2          / tbp_lv_perimeterMM **2\n    'hue_contrast',                      # tbp_lv_H                - tbp_lv_Hext              abs\n    'luminance_contrast',                # tbp_lv_L                - tbp_lv_Lext              abs\n    'lesion_color_difference',           # tbp_lv_deltaA **2       + tbp_lv_deltaB **2 + tbp_lv_deltaL **2  sqrt  \n    'border_complexity',                 # tbp_lv_norm_border      + tbp_lv_symm_2axis\n    'color_uniformity',                  # tbp_lv_color_std_mean   / tbp_lv_radial_color_std_max\n\n    'position_distance_3d',              # tbp_lv_x **2 + tbp_lv_y **2 + tbp_lv_z **2  sqrt\n    'perimeter_to_area_ratio',           # tbp_lv_perimeterMM      / tbp_lv_areaMM2\n    'area_to_perimeter_ratio',           # tbp_lv_areaMM2          / tbp_lv_perimeterMM\n    'lesion_visibility_score',           # tbp_lv_deltaLBnorm      + tbp_lv_norm_color\n    'symmetry_border_consistency',       # tbp_lv_symm_2axis       * tbp_lv_norm_border\n    'consistency_symmetry_border',       # tbp_lv_symm_2axis       * tbp_lv_norm_border / (tbp_lv_symm_2axis + tbp_lv_norm_border)\n\n    'color_consistency',                 # tbp_lv_stdL             / tbp_lv_Lext\n    'consistency_color',                 # tbp_lv_stdL*tbp_lv_Lext / tbp_lv_stdL + tbp_lv_Lext\n    'size_age_interaction',              # clin_size_long_diam_mm  * age_approx\n    'hue_color_std_interaction',         # tbp_lv_H                * tbp_lv_color_std_mean\n    'lesion_severity_index',             # tbp_lv_norm_border      + tbp_lv_norm_color + tbp_lv_eccentricity / 3\n    'shape_complexity_index',            # border_complexity       + lesion_shape_index\n    'color_contrast_index',              # tbp_lv_deltaA + tbp_lv_deltaB + tbp_lv_deltaL + tbp_lv_deltaLBnorm\n\n    'log_lesion_area',                   # tbp_lv_areaMM2          + 1  np.log\n    'normalized_lesion_size',            # clin_size_long_diam_mm  / age_approx\n    'mean_hue_difference',               # tbp_lv_H                + tbp_lv_Hext    / 2\n    'std_dev_contrast',                  # tbp_lv_deltaA **2 + tbp_lv_deltaB **2 + tbp_lv_deltaL **2   / 3  np.sqrt\n    'color_shape_composite_index',       # tbp_lv_color_std_mean   + bp_lv_area_perim_ratio + tbp_lv_symm_2axis   / 3\n    'lesion_orientation_3d',             # tbp_lv_y                , tbp_lv_x  np.arctan2\n    'overall_color_difference',          # tbp_lv_deltaA           + tbp_lv_deltaB + tbp_lv_deltaL   / 3\n\n    'symmetry_perimeter_interaction',    # tbp_lv_symm_2axis       * tbp_lv_perimeterMM\n    'comprehensive_lesion_index',        # tbp_lv_area_perim_ratio + tbp_lv_eccentricity + bp_lv_norm_color + tbp_lv_symm_2axis   / 4\n    'color_variance_ratio',              # tbp_lv_color_std_mean   / tbp_lv_stdLExt\n    'border_color_interaction',          # tbp_lv_norm_border      * tbp_lv_norm_color\n    'border_color_interaction_2',\n    'size_color_contrast_ratio',         # clin_size_long_diam_mm  / tbp_lv_deltaLBnorm\n    'age_normalized_nevi_confidence',    # tbp_lv_nevi_confidence  / age_approx\n    'age_normalized_nevi_confidence_2',\n    'color_asymmetry_index',             # tbp_lv_symm_2axis       * tbp_lv_radial_color_std_max\n\n    'volume_approximation_3d',           # tbp_lv_areaMM2          * sqrt(tbp_lv_x**2 + tbp_lv_y**2 + tbp_lv_z**2)\n    'color_range',                       # abs(tbp_lv_L - tbp_lv_Lext) + abs(tbp_lv_A - tbp_lv_Aext) + abs(tbp_lv_B - tbp_lv_Bext)\n    'shape_color_consistency',           # tbp_lv_eccentricity     * tbp_lv_color_std_mean\n    'border_length_ratio',               # tbp_lv_perimeterMM      / pi * sqrt(tbp_lv_areaMM2 / pi)\n    'age_size_symmetry_index',           # age_approx              * clin_size_long_diam_mm * tbp_lv_symm_2axis\n    'index_age_size_symmetry',           # age_approx              * tbp_lv_areaMM2 * tbp_lv_symm_2axis\n    \n#     'size_age_interaction2',             # tbp_lv_perimeterMM      * age_approx             / (sum)\n#     'hue_color_std_interaction2',        # tbp_lv_H                * tbp_lv_color_std_mean  / (sum)\n#     'symmetry_perim_interaction2',       # tbp_lv_symm_2axis       * clin_size_long_diam_mm / (sum)\n    \n#     'tbp_lv_ratio_A',\n#     'tbp_lv_ratio_B',\n#     'tbp_lv_ratio_C',\n#     'tbp_lv_ratio_H',\n#     'tbp_lv_ratio_L',\n    \n#     'tbp_lv_contrast_A',\n#     'tbp_lv_contrast_B',\n#     'tbp_lv_contrast_C',\n#     'tbp_lv_contrast_H',\n#     'tbp_lv_contrast_L',\n    \n#     'tbp_lv_patient_ratio_A',\n#     'tbp_lv_patient_ratio_B',\n#     'tbp_lv_patient_ratio_C',\n#     'tbp_lv_patient_ratio_H',\n#     'tbp_lv_patient_ratio_L',\n    \n#     'tbp_lv_patient_contrast_A',\n#     'tbp_lv_patient_contrast_B',\n#     'tbp_lv_patient_contrast_C',\n#     'tbp_lv_patient_contrast_H',\n#     'tbp_lv_patient_contrast_L',\n    \n#     'tbp_lv_age_ratio_A',\n#     'tbp_lv_age_ratio_B',\n#     'tbp_lv_age_ratio_C',\n#     'tbp_lv_age_ratio_H',\n#     'tbp_lv_age_ratio_L',\n    \n#     'tbp_lv_age_contrast_A',\n#     'tbp_lv_age_contrast_B',\n#     'tbp_lv_age_contrast_C',\n#     'tbp_lv_age_contrast_H',\n#     'tbp_lv_age_contrast_L',\n]\n\ncat_cols = ['sex', 'anatom_site_general', 'tbp_tile_type', 'tbp_lv_location', 'tbp_lv_location_simple', 'attribution']\nnorm_cols = [f'{col}_patient_norm' for col in num_cols + new_num_cols]\n# norm_cols2 = [f'{col}_sex_norm' for col in num_cols + new_num_cols]\nloc_norm_cols = [f'{col}_patient_location_norm' for col in num_cols + new_num_cols]\nanatom_norm_cols = [f'{col}_patient_anatom_norm' for col in num_cols + new_num_cols]\ntype_norm_cols = [f'{col}_patient_type_norm' for col in num_cols + new_num_cols]\n\nmax_col = [f'max_{col}' for col in num_cols + new_num_cols]\nmin_col = [f'min_{col}' for col in num_cols + new_num_cols]\nstd_col = [f'std_{col}' for col in num_cols + new_num_cols]\nsum_col = [f'sum_{col}' for col in num_cols + new_num_cols]\n\nspecial_cols = ['count_per_patient']\n\nfeature_cols = num_cols + new_num_cols + cat_cols + norm_cols + special_cols + loc_norm_cols","metadata":{"execution":{"iopub.status.busy":"2024-09-05T11:02:38.655772Z","iopub.execute_input":"2024-09-05T11:02:38.656559Z","iopub.status.idle":"2024-09-05T11:02:38.676502Z","shell.execute_reply.started":"2024-09-05T11:02:38.656519Z","shell.execute_reply":"2024-09-05T11:02:38.675469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Engineering","metadata":{}},{"cell_type":"code","source":"def read_data(path):\n    # df = pd.read_csv(path)\n    df = pd.read_csv(path, low_memory=False)\n    \n    df['sex'] = df['sex'].fillna('Unknown')\n    # df['sex'] = df['sex'].apply(lambda x: 'male' if x!='male' or x!='female' else x)\n    \n    return (\n        pl.from_pandas(df)\n        .with_columns(\n            pl.col('age_approx').cast(pl.String).replace('NA', np.nan).cast(pl.Float64),\n        )\n        .with_columns(\n            pl.col(pl.Float64).fill_nan(pl.col(pl.Float64).median()), # You may want to impute test data with train\n        )\n        .with_columns(\n            lesion_size_ratio              = pl.col('tbp_lv_minorAxisMM') / pl.col('clin_size_long_diam_mm'),\n            lesion_shape_index             = pl.col('tbp_lv_areaMM2') / (pl.col('tbp_lv_perimeterMM') ** 2),\n            hue_contrast                   = (pl.col('tbp_lv_H') - pl.col('tbp_lv_Hext')).abs(),\n            luminance_contrast             = (pl.col('tbp_lv_L') - pl.col('tbp_lv_Lext')).abs(),\n            lesion_color_difference        = (pl.col('tbp_lv_deltaA') ** 2 + pl.col('tbp_lv_deltaB') ** 2 + pl.col('tbp_lv_deltaL') ** 2).sqrt(),\n            border_complexity              = pl.col('tbp_lv_norm_border') + pl.col('tbp_lv_symm_2axis'),\n            color_uniformity               = pl.col('tbp_lv_color_std_mean') / (pl.col('tbp_lv_radial_color_std_max') + err),\n        )\n        .with_columns(\n            position_distance_3d           = (pl.col('tbp_lv_x') ** 2 + pl.col('tbp_lv_y') ** 2 + pl.col('tbp_lv_z') ** 2).sqrt(),\n            perimeter_to_area_ratio        = pl.col('tbp_lv_perimeterMM') / pl.col('tbp_lv_areaMM2'),\n            area_to_perimeter_ratio        = pl.col('tbp_lv_areaMM2') / pl.col('tbp_lv_perimeterMM'),\n            lesion_visibility_score        = pl.col('tbp_lv_deltaLBnorm') + pl.col('tbp_lv_norm_color'),\n            combined_anatomical_site       = pl.col('anatom_site_general') + '_' + pl.col('tbp_lv_location'),\n            symmetry_border_consistency    = pl.col('tbp_lv_symm_2axis') * pl.col('tbp_lv_norm_border'),\n            consistency_symmetry_border    = pl.col('tbp_lv_symm_2axis') * pl.col('tbp_lv_norm_border') / (pl.col('tbp_lv_symm_2axis') + pl.col('tbp_lv_norm_border')),\n        )\n        .with_columns(\n            color_consistency              = pl.col('tbp_lv_stdL') / pl.col('tbp_lv_Lext'),\n            consistency_color              = pl.col('tbp_lv_stdL') * pl.col('tbp_lv_Lext') / (pl.col('tbp_lv_stdL') + pl.col('tbp_lv_Lext')),\n            size_age_interaction           = pl.col('clin_size_long_diam_mm') * pl.col('age_approx'),\n            hue_color_std_interaction      = pl.col('tbp_lv_H') * pl.col('tbp_lv_color_std_mean'),\n            lesion_severity_index          = (pl.col('tbp_lv_norm_border') + pl.col('tbp_lv_norm_color') + pl.col('tbp_lv_eccentricity')) / 3,\n            shape_complexity_index         = pl.col('border_complexity') + pl.col('lesion_shape_index'),\n            color_contrast_index           = pl.col('tbp_lv_deltaA') + pl.col('tbp_lv_deltaB') + pl.col('tbp_lv_deltaL') + pl.col('tbp_lv_deltaLBnorm'),\n        )\n        .with_columns(\n            log_lesion_area                = (pl.col('tbp_lv_areaMM2') + 1).log(),\n            normalized_lesion_size         = pl.col('clin_size_long_diam_mm') / pl.col('age_approx'),\n            mean_hue_difference            = (pl.col('tbp_lv_H') + pl.col('tbp_lv_Hext')) / 2,\n            std_dev_contrast               = ((pl.col('tbp_lv_deltaA') ** 2 + pl.col('tbp_lv_deltaB') ** 2 + pl.col('tbp_lv_deltaL') ** 2) / 3).sqrt(),\n            color_shape_composite_index    = (pl.col('tbp_lv_color_std_mean') + pl.col('tbp_lv_area_perim_ratio') + pl.col('tbp_lv_symm_2axis')) / 3,\n            lesion_orientation_3d          = pl.arctan2(pl.col('tbp_lv_y'), pl.col('tbp_lv_x')),\n            overall_color_difference       = (pl.col('tbp_lv_deltaA') + pl.col('tbp_lv_deltaB') + pl.col('tbp_lv_deltaL')) / 3,\n        )\n        .with_columns(\n            symmetry_perimeter_interaction = pl.col('tbp_lv_symm_2axis') * pl.col('tbp_lv_perimeterMM'),\n            comprehensive_lesion_index     = (pl.col('tbp_lv_area_perim_ratio') + pl.col('tbp_lv_eccentricity') + pl.col('tbp_lv_norm_color') + pl.col('tbp_lv_symm_2axis')) / 4,\n            color_variance_ratio           = pl.col('tbp_lv_color_std_mean') / pl.col('tbp_lv_stdLExt'),\n            border_color_interaction       = pl.col('tbp_lv_norm_border') * pl.col('tbp_lv_norm_color'),\n            border_color_interaction_2     = pl.col('tbp_lv_norm_border') * pl.col('tbp_lv_norm_color') / (pl.col('tbp_lv_norm_border') + pl.col('tbp_lv_norm_color')),\n            size_color_contrast_ratio      = pl.col('clin_size_long_diam_mm') / pl.col('tbp_lv_deltaLBnorm'),\n            age_normalized_nevi_confidence = pl.col('tbp_lv_nevi_confidence') / pl.col('age_approx'),\n            age_normalized_nevi_confidence_2 = (pl.col('clin_size_long_diam_mm')**2 + pl.col('age_approx')**2).sqrt(),\n            color_asymmetry_index          = pl.col('tbp_lv_radial_color_std_max') * pl.col('tbp_lv_symm_2axis'),\n        )\n        .with_columns(\n            volume_approximation_3d        = pl.col('tbp_lv_areaMM2') * (pl.col('tbp_lv_x')**2 + pl.col('tbp_lv_y')**2 + pl.col('tbp_lv_z')**2).sqrt(),\n            color_range                    = (pl.col('tbp_lv_L') - pl.col('tbp_lv_Lext')).abs() + (pl.col('tbp_lv_A') - pl.col('tbp_lv_Aext')).abs() + (pl.col('tbp_lv_B') - pl.col('tbp_lv_Bext')).abs(),\n            shape_color_consistency        = pl.col('tbp_lv_eccentricity') * pl.col('tbp_lv_color_std_mean'),\n            border_length_ratio            = pl.col('tbp_lv_perimeterMM') / (2 * np.pi * (pl.col('tbp_lv_areaMM2') / np.pi).sqrt()),\n            age_size_symmetry_index        = pl.col('age_approx') * pl.col('clin_size_long_diam_mm') * pl.col('tbp_lv_symm_2axis'),\n            index_age_size_symmetry        = pl.col('age_approx') * pl.col('tbp_lv_areaMM2') * pl.col('tbp_lv_symm_2axis'),\n        )\n        .with_columns(\n            # ((pl.col(col) - pl.col(col).mean().over('patient_id')) / (pl.col(col).std().over('patient_id') + err)).alias(f'{col}_patient_norm') for col in (num_cols)\n            ((pl.col(col) - pl.col(col).mean().over('patient_id')) / (pl.col(col).std().over('patient_id') + err)).alias(f'{col}_patient_norm') for col in (num_cols + new_num_cols)\n        )\n        .with_columns(\n            ((pl.col(col) - pl.col(col).mean().over(['patient_id', 'tbp_lv_location'])) / (pl.col(col).std().over(['patient_id', 'tbp_lv_location']) + err)).alias(f'{col}_patient_location_norm') for col in (num_cols + new_num_cols)\n        )\n        # .with_columns(\n        #     ((pl.col(col) - pl.col(col).mean().over(['patient_id', 'anatom_site_general'])) / (pl.col(col).std().over(['patient_id', 'anatom_site_general']) + err)).alias(f'{col}_patient_anatom_norm') for col in (num_cols + new_num_cols)\n        # )\n        # .with_columns(\n        #     ((pl.col(col) - pl.col(col).mean().over(['patient_id', 'tbp_tile_type'])) / (pl.col(col).std().over(['patient_id', 'tbp_tile_type']) + err)).alias(f'{col}_patient_type_norm') for col in (num_cols + new_num_cols)\n        # )\n        # .with_columns(\n        #     ((pl.col(col) - pl.col(col).mean().over('sex')) / (pl.col(col).std().over('sex') + err)).alias(f'{col}_sex_norm') for col in (num_cols + new_num_cols)\n        # )\n        .with_columns(\n            count_per_patient = pl.col('isic_id').count().over('patient_id'),\n        )\n        .with_columns(\n            pl.col(cat_cols).cast(pl.Categorical),\n        )\n        # .with_columns(\n        #     pl.col(col).max().over(['patient_id', 'tbp_lv_location']).alias(f'max_{col}') for col in (num_cols + new_num_cols)\n        # )\n        # .with_columns(\n        #     pl.col(col).max().over(['patient_id', 'tbp_lv_location']).alias(f'min_{col}') for col in (num_cols + new_num_cols)\n        # )\n        # .with_columns(\n        #     pl.col(col).max().over(['patient_id', 'tbp_lv_location']).alias(f'std_{col}') for col in (num_cols + new_num_cols)\n        # )\n        # .with_columns(\n        #     pl.col(col).max().over(['patient_id', 'tbp_lv_location']).alias(f'sum_{col}') for col in (num_cols + new_num_cols)\n        # )\n        \n        .to_pandas()\n        .set_index(id_col)\n    )","metadata":{"execution":{"iopub.status.busy":"2024-09-05T11:02:38.678387Z","iopub.execute_input":"2024-09-05T11:02:38.678805Z","iopub.status.idle":"2024-09-05T11:02:38.712028Z","shell.execute_reply.started":"2024-09-05T11:02:38.678758Z","shell.execute_reply":"2024-09-05T11:02:38.711036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess(df_train, df_test):\n    global cat_cols\n    \n    encoder = OneHotEncoder(sparse_output=False, dtype=np.int32, handle_unknown='ignore')\n    encoder.fit(df_train[cat_cols])\n    \n    new_cat_cols = [f'onehot_{i}' for i in range(len(encoder.get_feature_names_out()))]\n\n    df_train[new_cat_cols] = encoder.transform(df_train[cat_cols])\n    df_train[new_cat_cols] = df_train[new_cat_cols].astype('category')\n\n    df_test[new_cat_cols] = encoder.transform(df_test[cat_cols])\n    df_test[new_cat_cols] = df_test[new_cat_cols].astype('category')\n\n    for col in cat_cols:\n        feature_cols.remove(col)\n\n    feature_cols.extend(new_cat_cols)\n    cat_cols = new_cat_cols\n    \n    return df_train, df_test","metadata":{"execution":{"iopub.status.busy":"2024-09-05T11:02:38.713157Z","iopub.execute_input":"2024-09-05T11:02:38.713467Z","iopub.status.idle":"2024-09-05T11:02:38.726346Z","shell.execute_reply.started":"2024-09-05T11:02:38.713434Z","shell.execute_reply":"2024-09-05T11:02:38.725316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Read Data","metadata":{}},{"cell_type":"code","source":"df_train = read_data(train_path)\ndf_test = read_data(test_path)\ndf_subm = pd.read_csv(subm_path, index_col=id_col)\n\ndf_train, df_test = preprocess(df_train, df_test)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T11:02:38.727565Z","iopub.execute_input":"2024-09-05T11:02:38.727913Z","iopub.status.idle":"2024-09-05T11:02:57.351160Z","shell.execute_reply.started":"2024-09-05T11:02:38.727880Z","shell.execute_reply":"2024-09-05T11:02:57.350337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ML-Model lgb-xgb-catgb","metadata":{}},{"cell_type":"code","source":"# lgb_params = {\n#     'objective':        'binary',\n#     'verbosity':        -1,\n#     'n_iter':           250,\n#     'boosting_type':    'gbdt',\n#     'random_state':     None,\n#     'lambda_l1':        0.08758718919397321, \n#     'lambda_l2':        0.0039689175176025465, \n#     'learning_rate':    0.03231007103195577, \n#     'max_depth':        4, \n#     'num_leaves':       103, \n#     'colsample_bytree': 0.8329551585827726, \n#     'colsample_bynode': 0.4025961355653304, \n#     'bagging_fraction': 0.7738954452473223, \n#     'bagging_freq':     4, \n#     'min_data_in_leaf': 85, \n#     'scale_pos_weight': 2.7984184778875543,\n# }","metadata":{"execution":{"iopub.status.busy":"2024-09-05T11:02:57.352380Z","iopub.execute_input":"2024-09-05T11:02:57.352714Z","iopub.status.idle":"2024-09-05T11:02:57.357293Z","shell.execute_reply.started":"2024-09-05T11:02:57.352678Z","shell.execute_reply":"2024-09-05T11:02:57.356394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cb_params = {\n#     'loss_function':     'Logloss',\n#     'iterations':        250,\n#     'verbose':           False,\n#     'random_state':      None,\n#     'max_depth':         7, \n#     'learning_rate':     0.06936242010150652, \n#     'scale_pos_weight':  2.6149345838209532, \n#     'l2_leaf_reg':       6.216113851699493, \n#     'subsample':         0.6249261779711819, \n#     'min_data_in_leaf':  24,\n#     'cat_features':      cat_cols,\n# }","metadata":{"execution":{"iopub.status.busy":"2024-09-05T11:02:57.358637Z","iopub.execute_input":"2024-09-05T11:02:57.359287Z","iopub.status.idle":"2024-09-05T11:02:57.369024Z","shell.execute_reply.started":"2024-09-05T11:02:57.359253Z","shell.execute_reply":"2024-09-05T11:02:57.368059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# xgb_params = {\n#     'enable_categorical': True,\n#     'tree_method':        'hist',\n#     'random_state':       None,\n#     'learning_rate':      0.08501257473292347, \n#     'lambda':             8.879624125465703, \n#     'alpha':              0.6779926606782505, \n#     'max_depth':          6, \n#     'subsample':          0.6012681388711075, \n#     'colsample_bytree':   0.8437772277074493, \n#     'colsample_bylevel':  0.5476090898823716, \n#     'colsample_bynode':   0.9928601203635129, \n#     'scale_pos_weight':   3.29440313334688,\n# }","metadata":{"execution":{"iopub.status.busy":"2024-09-05T11:02:57.370161Z","iopub.execute_input":"2024-09-05T11:02:57.370456Z","iopub.status.idle":"2024-09-05T11:02:57.381383Z","shell.execute_reply.started":"2024-09-05T11:02:57.370425Z","shell.execute_reply":"2024-09-05T11:02:57.380391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Make DL Features","metadata":{}},{"cell_type":"code","source":"df_test[CONFIG.dl_pred_name] = total_test_pred\ndf_test","metadata":{"execution":{"iopub.status.busy":"2024-09-05T11:02:57.382637Z","iopub.execute_input":"2024-09-05T11:02:57.382921Z","iopub.status.idle":"2024-09-05T11:02:57.416990Z","shell.execute_reply.started":"2024-09-05T11:02:57.382890Z","shell.execute_reply":"2024-09-05T11:02:57.416071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load ML Models","metadata":{}},{"cell_type":"code","source":"models = []\nall_gbdt_paths = {}\nfor now_seed in CONFIG.n_seed:\n    all_gbdt_paths[now_seed] = []\n\ngbdt_paths = sorted(os.listdir(GBDT_ckpt_paths))\nfor path in gbdt_paths:\n    path_seed = int(path.split(\"_\")[1])\n    all_gbdt_paths[path_seed].append(path)\n\nfor now_seed in CONFIG.n_seed:\n    gbdt_paths = all_gbdt_paths[now_seed]\n    # 从文件加载模型\n    for fold in range(CONFIG.n_folds):\n        # 从文件加载模型\n        print(f\"{gbdt_paths[fold]}\")\n        loaded_estimator = load(f'{GBDT_ckpt_paths}/{gbdt_paths[fold]}')\n        models.append(loaded_estimator)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T11:02:57.418059Z","iopub.execute_input":"2024-09-05T11:02:57.418387Z","iopub.status.idle":"2024-09-05T11:03:00.633369Z","shell.execute_reply.started":"2024-09-05T11:02:57.418352Z","shell.execute_reply":"2024-09-05T11:03:00.632196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Start Infer","metadata":{}},{"cell_type":"code","source":"feature_cols.append(CONFIG.dl_pred_name)\nlen(feature_cols)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T11:03:00.638632Z","iopub.execute_input":"2024-09-05T11:03:00.639003Z","iopub.status.idle":"2024-09-05T11:03:00.645517Z","shell.execute_reply.started":"2024-09-05T11:03:00.638965Z","shell.execute_reply":"2024-09-05T11:03:00.644503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_pred = []\nfor fold in tqdm(range(CONFIG.n_folds * len(CONFIG.n_seed))):\n    estimator = models[fold]\n    preds = estimator.predict_proba(df_test[feature_cols])[:, 1]\n    total_pred.append(preds)\n    \ntotal_pred = np.mean(total_pred, axis=0)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T11:03:00.646895Z","iopub.execute_input":"2024-09-05T11:03:00.647224Z","iopub.status.idle":"2024-09-05T11:03:03.846028Z","shell.execute_reply.started":"2024-09-05T11:03:00.647188Z","shell.execute_reply":"2024-09-05T11:03:03.845086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Make submission","metadata":{}},{"cell_type":"code","source":"df_subm['target'] = total_pred\n\ndf_subm.to_csv('submission.csv')\ndf_subm.head()","metadata":{"execution":{"iopub.status.busy":"2024-09-05T11:03:03.847248Z","iopub.execute_input":"2024-09-05T11:03:03.847612Z","iopub.status.idle":"2024-09-05T11:03:03.862283Z","shell.execute_reply.started":"2024-09-05T11:03:03.847575Z","shell.execute_reply":"2024-09-05T11:03:03.861478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}