{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":63056,"databundleVersionId":9094797,"sourceType":"competition"},{"sourceId":9259236,"sourceType":"datasetVersion","datasetId":5602402}],"dockerImageVersionId":30747,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import Libs","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"import os\nimport random\nimport gc\nimport time\nimport copy\nimport sys\nimport numpy as np\nimport pandas as pd\nimport h5py\nfrom io import BytesIO\n\nfrom torch.utils.data import Dataset, DataLoader\nimport torch\nimport torch.nn.functional as F\nfrom torch import nn\nimport timm\n\nfrom PIL import Image\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom tqdm import tqdm\nfrom collections import defaultdict\n\nimport warnings # 避免一些可以忽略的报错\nwarnings.filterwarnings('ignore')\n# For colored terminal text\nfrom colorama import Fore, Back, Style\nb_ = Fore.BLUE\nsr_ = Style.RESET_ALL","metadata":{"execution":{"iopub.status.busy":"2024-08-30T05:46:55.787381Z","iopub.execute_input":"2024-08-30T05:46:55.787994Z","iopub.status.idle":"2024-08-30T05:47:07.380535Z","shell.execute_reply.started":"2024-08-30T05:46:55.787962Z","shell.execute_reply":"2024-08-30T05:47:07.379551Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## CONFIG","metadata":{}},{"cell_type":"code","source":"is_debug = False\n\nclass CONFIG:\n    seed = 308\n    \n    # 256 tiny_vit ---------- 3h+\n    # 512 efficientnet convnext -------------- 17mins+\n    #     efficientvit_b0 --------------- 7mins+\n    test_batch_size = 512\n    img_size = [160, 160]\n    n_classes = 1\n    n_folds = 5\n    \n    n_accumulate = 1.0\n    n_workers = os.cpu_count()\n\n    DataParallel = True\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n    \"\"\"\n    tf_efficientnet_b0_ns\n    tiny_vit_21m_512.dist_in22k_ft_in1k\n    eva02_base_patch14_224.mim_in22k\n    convnext_tiny.fb_in22k_ft_in1k_384\n    tf_efficientnetv2_s.in21k_ft_in1k\n    efficientvit_b0.r224_in1k\n    \n    edgenext_base.in21k_ft_in1k\n    \"\"\"\n    model_name = \"tf_efficientnetv2_s.in21k_ft_in1k\"\n    ckpt_path = \"/kaggle/input/20240827-efficientnetv2s-train1954-cv15496\"\n    use_gempool = False\n\n    test_csv = \"/kaggle/input/isic-2024-challenge/test-metadata.csv\"\n    test_img_hdf5 = \"/kaggle/input/isic-2024-challenge/test-image.hdf5\"\n    \n#     # debug\n#     test_csv = \"/kaggle/input/isic-2024-challenge/train-metadata.csv\"\n#     test_img_hdf5 = \"/kaggle/input/isic-2024-challenge/train-image.hdf5\"\n\nif CONFIG.DataParallel:\n    os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'\n    print(\"IN DataParallel!\")\nelse:\n    os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n    print(\"NO IN DataParallel!\")","metadata":{"execution":{"iopub.status.busy":"2024-08-30T05:47:07.382353Z","iopub.execute_input":"2024-08-30T05:47:07.382882Z","iopub.status.idle":"2024-08-30T05:47:07.437937Z","shell.execute_reply.started":"2024-08-30T05:47:07.382856Z","shell.execute_reply":"2024-08-30T05:47:07.437096Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"IN DataParallel!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Set Random Seed","metadata":{}},{"cell_type":"code","source":"def set_seed(seed=308):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\nset_seed(CONFIG.seed)","metadata":{"execution":{"iopub.status.busy":"2024-08-30T05:47:07.438998Z","iopub.execute_input":"2024-08-30T05:47:07.439272Z","iopub.status.idle":"2024-08-30T05:47:07.460992Z","shell.execute_reply.started":"2024-08-30T05:47:07.439248Z","shell.execute_reply":"2024-08-30T05:47:07.460139Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Data Progress","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv(CONFIG.test_csv)\ntest","metadata":{"execution":{"iopub.status.busy":"2024-08-30T05:47:07.462897Z","iopub.execute_input":"2024-08-30T05:47:07.463159Z","iopub.status.idle":"2024-08-30T05:47:07.535641Z","shell.execute_reply.started":"2024-08-30T05:47:07.463137Z","shell.execute_reply":"2024-08-30T05:47:07.534715Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"        isic_id  patient_id  age_approx     sex anatom_site_general  \\\n0  ISIC_0015657  IP_6074337        45.0    male     posterior torso   \n1  ISIC_0015729  IP_1664139        35.0  female     lower extremity   \n2  ISIC_0015740  IP_7142616        65.0    male     posterior torso   \n\n   clin_size_long_diam_mm          image_type tbp_tile_type  tbp_lv_A  \\\n0                    2.70  TBP tile: close-up        3D: XP  22.80433   \n1                    2.52  TBP tile: close-up        3D: XP  16.64867   \n2                    3.16  TBP tile: close-up        3D: XP  24.25384   \n\n   tbp_lv_Aext  ...  tbp_lv_radial_color_std_max  tbp_lv_stdL  tbp_lv_stdLExt  \\\n0    20.007270  ...                     0.304827     1.281532        2.299935   \n1     9.657964  ...                     0.000000     1.271940        2.011223   \n2    19.937380  ...                     0.230742     1.080308        2.705857   \n\n   tbp_lv_symm_2axis  tbp_lv_symm_2axis_angle   tbp_lv_x     tbp_lv_y  \\\n0           0.479339                       20 -155.06510  1511.222000   \n1           0.426230                       25 -112.36924   629.535889   \n2           0.366071                      110  -84.29282  1303.978000   \n\n     tbp_lv_z                                        attribution  \\\n0  113.980100             Memorial Sloan Kettering Cancer Center   \n1  -15.019287  Frazer Institute, The University of Queensland...   \n2  -28.576050                                        FNQH Cairns   \n\n   copyright_license  \n0              CC-BY  \n1              CC-BY  \n2              CC-BY  \n\n[3 rows x 44 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>isic_id</th>\n      <th>patient_id</th>\n      <th>age_approx</th>\n      <th>sex</th>\n      <th>anatom_site_general</th>\n      <th>clin_size_long_diam_mm</th>\n      <th>image_type</th>\n      <th>tbp_tile_type</th>\n      <th>tbp_lv_A</th>\n      <th>tbp_lv_Aext</th>\n      <th>...</th>\n      <th>tbp_lv_radial_color_std_max</th>\n      <th>tbp_lv_stdL</th>\n      <th>tbp_lv_stdLExt</th>\n      <th>tbp_lv_symm_2axis</th>\n      <th>tbp_lv_symm_2axis_angle</th>\n      <th>tbp_lv_x</th>\n      <th>tbp_lv_y</th>\n      <th>tbp_lv_z</th>\n      <th>attribution</th>\n      <th>copyright_license</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ISIC_0015657</td>\n      <td>IP_6074337</td>\n      <td>45.0</td>\n      <td>male</td>\n      <td>posterior torso</td>\n      <td>2.70</td>\n      <td>TBP tile: close-up</td>\n      <td>3D: XP</td>\n      <td>22.80433</td>\n      <td>20.007270</td>\n      <td>...</td>\n      <td>0.304827</td>\n      <td>1.281532</td>\n      <td>2.299935</td>\n      <td>0.479339</td>\n      <td>20</td>\n      <td>-155.06510</td>\n      <td>1511.222000</td>\n      <td>113.980100</td>\n      <td>Memorial Sloan Kettering Cancer Center</td>\n      <td>CC-BY</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ISIC_0015729</td>\n      <td>IP_1664139</td>\n      <td>35.0</td>\n      <td>female</td>\n      <td>lower extremity</td>\n      <td>2.52</td>\n      <td>TBP tile: close-up</td>\n      <td>3D: XP</td>\n      <td>16.64867</td>\n      <td>9.657964</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>1.271940</td>\n      <td>2.011223</td>\n      <td>0.426230</td>\n      <td>25</td>\n      <td>-112.36924</td>\n      <td>629.535889</td>\n      <td>-15.019287</td>\n      <td>Frazer Institute, The University of Queensland...</td>\n      <td>CC-BY</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ISIC_0015740</td>\n      <td>IP_7142616</td>\n      <td>65.0</td>\n      <td>male</td>\n      <td>posterior torso</td>\n      <td>3.16</td>\n      <td>TBP tile: close-up</td>\n      <td>3D: XP</td>\n      <td>24.25384</td>\n      <td>19.937380</td>\n      <td>...</td>\n      <td>0.230742</td>\n      <td>1.080308</td>\n      <td>2.705857</td>\n      <td>0.366071</td>\n      <td>110</td>\n      <td>-84.29282</td>\n      <td>1303.978000</td>\n      <td>-28.576050</td>\n      <td>FNQH Cairns</td>\n      <td>CC-BY</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 44 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Dataset and DataLoader","metadata":{}},{"cell_type":"code","source":"def transform(img):\n    composition = A.Compose([\n        A.Resize(CONFIG.img_size[0], CONFIG.img_size[1]),\n        A.Normalize(),\n        ToTensorV2(),\n    ])\n    return composition(image=img)[\"image\"]","metadata":{"execution":{"iopub.status.busy":"2024-08-30T05:47:07.536663Z","iopub.execute_input":"2024-08-30T05:47:07.536934Z","iopub.status.idle":"2024-08-30T05:47:07.542308Z","shell.execute_reply.started":"2024-08-30T05:47:07.536912Z","shell.execute_reply":"2024-08-30T05:47:07.541334Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class MyDataset(Dataset):\n    def __init__(self, df, transform=None):\n        super().__init__()\n        self.df = df\n        self.fp_hdf = h5py.File(CONFIG.test_img_hdf5, mode=\"r\")\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx, :]\n        img_id = row.isic_id\n        label = str(img_id)\n        \n        img = np.array( Image.open(BytesIO(self.fp_hdf[img_id][()])) )\n        img = np.array(img).astype(np.float32)\n\n        if self.transform != None:\n            img = self.transform(img)\n\n        return img, label","metadata":{"execution":{"iopub.status.busy":"2024-08-30T05:47:07.543398Z","iopub.execute_input":"2024-08-30T05:47:07.543710Z","iopub.status.idle":"2024-08-30T05:47:07.554743Z","shell.execute_reply.started":"2024-08-30T05:47:07.543686Z","shell.execute_reply":"2024-08-30T05:47:07.553931Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def prepare_loaders(df):\n    \n    test_datasets = MyDataset(df=df, transform=transform)\n    \n    test_loader = DataLoader(test_datasets, batch_size=CONFIG.test_batch_size, num_workers=CONFIG.n_workers, shuffle=False, pin_memory=True)\n    \n    return test_loader","metadata":{"execution":{"iopub.status.busy":"2024-08-30T05:47:07.555858Z","iopub.execute_input":"2024-08-30T05:47:07.556228Z","iopub.status.idle":"2024-08-30T05:47:07.565066Z","shell.execute_reply.started":"2024-08-30T05:47:07.556198Z","shell.execute_reply":"2024-08-30T05:47:07.564323Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# test_loader = prepare_loaders(test)\n# x, y = next(iter(test_loader))\n# x.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-30T05:47:07.566085Z","iopub.execute_input":"2024-08-30T05:47:07.566327Z","iopub.status.idle":"2024-08-30T05:47:07.573344Z","shell.execute_reply.started":"2024-08-30T05:47:07.566307Z","shell.execute_reply":"2024-08-30T05:47:07.572657Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## DL Model","metadata":{}},{"cell_type":"code","source":"def updata_req_grad(models, requires_grad=True):\n    for model in models:\n        for param in model.parameters():\n            param.requires_grad = requires_grad","metadata":{"execution":{"iopub.status.busy":"2024-08-27T13:12:09.753659Z","iopub.execute_input":"2024-08-27T13:12:09.753983Z","iopub.status.idle":"2024-08-27T13:12:09.760703Z","shell.execute_reply.started":"2024-08-27T13:12:09.753937Z","shell.execute_reply":"2024-08-27T13:12:09.759592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class GeMPool(nn.Module):\n    def __init__(self, p=3, eps=1e-6):\n        super(GeMPool, self).__init__()\n        self.p = nn.Parameter(torch.ones(1) * p)\n        self.eps = eps\n\n    def forward(self, x):\n        return self.gem(x, p=self.p, eps=self.eps)\n    \n    def gem(self, x, p=3, eps=1e-6):\n        return torch.mean(x.clamp(min=eps).pow(p), dim=(-2, -1)).pow(1./p)\n    \n    def __repr__(self):\n        return self.__class__.__name__ + f'(p={self.p.data.tolist()[0]:.4f}, eps={self.eps})'","metadata":{"execution":{"iopub.status.busy":"2024-08-27T13:12:09.764197Z","iopub.execute_input":"2024-08-27T13:12:09.764598Z","iopub.status.idle":"2024-08-27T13:12:09.773266Z","shell.execute_reply.started":"2024-08-27T13:12:09.764569Z","shell.execute_reply":"2024-08-27T13:12:09.772153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ISIC2024Model(nn.Module):\n    def __init__(self):\n        super(ISIC2024Model, self).__init__()\n        self.backbone = timm.create_model(model_name=CONFIG.model_name, \n                                          pretrained=False)\n        \n        if \"efficientnet\" in CONFIG.model_name:\n            in_features = self.backbone.classifier.in_features\n            self.backbone.classifier = nn.Identity()\n            if CONFIG.use_gempool:\n                self.backbone.global_pool = GeMPool()\n        elif \"convnext\" in CONFIG.model_name or \"tiny_vit\" in CONFIG.model_name:\n            in_features = self.backbone.head.fc.in_features\n            self.backbone.head.fc = nn.Identity()\n        elif \"eva\" in CONFIG.model_name:\n            in_features = 768\n        elif \"efficientvit\" in CONFIG.model_name:\n            in_features = self.backbone.head.classifier[4].in_features\n            self.backbone.head.classifier[4] = nn.Identity()\n        elif \"edgenext\" in CONFIG.model_name:\n            in_features = self.backbone.head.fc.in_features\n            self.backbone.head.fc = nn.Identity()\n\n        self.head = nn.Sequential(\n            nn.Linear(in_features, CONFIG.n_classes)\n        )\n        \n    def forward(self, x):\n        _tmp = self.backbone(x)\n        output = self.head(_tmp)\n        return output","metadata":{"execution":{"iopub.status.busy":"2024-08-27T13:12:09.774644Z","iopub.execute_input":"2024-08-27T13:12:09.775294Z","iopub.status.idle":"2024-08-27T13:12:09.787262Z","shell.execute_reply.started":"2024-08-27T13:12:09.775265Z","shell.execute_reply":"2024-08-27T13:12:09.786240Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = ISIC2024Model()\nmodel","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-27T13:12:09.788600Z","iopub.execute_input":"2024-08-27T13:12:09.788927Z","iopub.status.idle":"2024-08-27T13:12:10.373263Z","shell.execute_reply.started":"2024-08-27T13:12:09.788882Z","shell.execute_reply":"2024-08-27T13:12:10.372249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Models","metadata":{}},{"cell_type":"code","source":"models = []\n\npaths = os.listdir(CONFIG.ckpt_path)\n# paths = [\"1_CV0.1547_Loss0.6784_epoch2.bin\",\n#          \"2_CV0.1708_Loss0.5088_epoch5.bin\",\n#          \"3_CV0.1791_Loss0.3739_epoch7.bin\",\n#          \"4_CV0.1654_Loss0.5382_epoch3.bin\",\n#          \"5_CV0.1812_Loss0.4236_epoch8.bin\"]\n\nif CONFIG.DataParallel:\n    device_ids = [0, 1]\n    for i in range(CONFIG.n_folds):\n        model = ISIC2024Model()\n        model = torch.nn.DataParallel(model, device_ids=device_ids)\n        model = model.cuda()\n        model.load_state_dict(torch.load(os.path.join(CONFIG.ckpt_path, paths[i])))\n        model.eval()\n        models.append(model)\nelse:\n    for i in range(CONFIG.n_folds):\n        model = ISIC2024Model()\n        model = model.cuda()\n        model.load_state_dict(torch.load(os.path.join(CONFIG.ckpt_path, paths[i])))\n        model.eval()\n        models.append(model)","metadata":{"execution":{"iopub.status.busy":"2024-08-27T13:12:10.374864Z","iopub.execute_input":"2024-08-27T13:12:10.375148Z","iopub.status.idle":"2024-08-27T13:12:19.211487Z","shell.execute_reply.started":"2024-08-27T13:12:10.375123Z","shell.execute_reply":"2024-08-27T13:12:19.210386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Infer Function","metadata":{}},{"cell_type":"code","source":"def Infer(models, test_loader):\n    y_preds = []\n    bar = tqdm(enumerate(test_loader), total=len(test_loader))\n    with torch.no_grad():\n        for step, (images, study_id) in bar:\n            \n            if CONFIG.DataParallel:\n                images = images.cuda().float()\n            else:\n                images = images.to(CONFIG.device, dtype=torch.float)\n                \n            outputs = 0\n                \n            for model in models:\n                output = model(images)\n                outputs += output\n            outputs = outputs / len(models)\n            outputs = F.sigmoid(outputs)\n            y_preds.append(outputs.detach().flatten().cpu().numpy())\n            \n    y_preds = np.concatenate(y_preds)\n    return y_preds","metadata":{"execution":{"iopub.status.busy":"2024-08-27T13:12:19.213340Z","iopub.execute_input":"2024-08-27T13:12:19.214615Z","iopub.status.idle":"2024-08-27T13:12:19.223191Z","shell.execute_reply.started":"2024-08-27T13:12:19.214583Z","shell.execute_reply":"2024-08-27T13:12:19.222072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Start Infer","metadata":{}},{"cell_type":"code","source":"test_loader = prepare_loaders(test)\n\npreds = Infer(models, test_loader)","metadata":{"execution":{"iopub.status.busy":"2024-08-27T13:12:19.224654Z","iopub.execute_input":"2024-08-27T13:12:19.225050Z","iopub.status.idle":"2024-08-27T13:12:22.090346Z","shell.execute_reply.started":"2024-08-27T13:12:19.225014Z","shell.execute_reply":"2024-08-27T13:12:22.089054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Make Submission","metadata":{}},{"cell_type":"code","source":"sub = pd.DataFrame()\nsub['isic_id'] = test[\"isic_id\"]\nsub['target'] = preds\nsub.head(25)","metadata":{"execution":{"iopub.status.busy":"2024-08-27T13:12:22.091912Z","iopub.execute_input":"2024-08-27T13:12:22.092241Z","iopub.status.idle":"2024-08-27T13:12:22.113942Z","shell.execute_reply.started":"2024-08-27T13:12:22.092210Z","shell.execute_reply":"2024-08-27T13:12:22.112894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.to_csv('submission.csv', index=False)\npd.read_csv('submission.csv').head()","metadata":{"execution":{"iopub.status.busy":"2024-08-27T13:12:22.115570Z","iopub.execute_input":"2024-08-27T13:12:22.116012Z","iopub.status.idle":"2024-08-27T13:12:22.134173Z","shell.execute_reply.started":"2024-08-27T13:12:22.115971Z","shell.execute_reply":"2024-08-27T13:12:22.133122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}