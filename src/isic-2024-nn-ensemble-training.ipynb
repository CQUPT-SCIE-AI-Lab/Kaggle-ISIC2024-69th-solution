{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":63056,"databundleVersionId":9094797,"sourceType":"competition"},{"sourceId":9252981,"sourceType":"datasetVersion","datasetId":5598094},{"sourceId":9259236,"sourceType":"datasetVersion","datasetId":5602402},{"sourceId":9265228,"sourceType":"datasetVersion","datasetId":5606682},{"sourceId":9273501,"sourceType":"datasetVersion","datasetId":5612311},{"sourceId":9273517,"sourceType":"datasetVersion","datasetId":5612326},{"sourceId":9273532,"sourceType":"datasetVersion","datasetId":5612338},{"sourceId":9342639,"sourceType":"datasetVersion","datasetId":5662020},{"sourceId":9342668,"sourceType":"datasetVersion","datasetId":5662044}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import Libs","metadata":{}},{"cell_type":"code","source":"import os\nimport random\nimport gc\nimport time\nimport copy\nimport sys\nimport math\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2\n\nfrom torch.utils.data import Dataset, DataLoader\nimport torch\nimport torch.nn.functional as F\nfrom torch import nn\nfrom torch.optim import lr_scheduler\nfrom torch.optim.lr_scheduler import _LRScheduler, CosineAnnealingLR\nimport timm\n\nfrom PIL import Image\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom tqdm import tqdm\nfrom collections import defaultdict\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_curve, auc, roc_auc_score\n\nimport warnings # 避免一些可以忽略的报错\nwarnings.filterwarnings('ignore')\n# For colored terminal text\nfrom colorama import Fore, Back, Style\nb_ = Fore.BLUE\nsr_ = Style.RESET_ALL","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-09-08T06:18:32.849083Z","iopub.execute_input":"2024-09-08T06:18:32.849492Z","iopub.status.idle":"2024-09-08T06:18:40.641777Z","shell.execute_reply.started":"2024-09-08T06:18:32.849451Z","shell.execute_reply":"2024-09-08T06:18:40.640978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## CONFIG","metadata":{}},{"cell_type":"code","source":"is_debug = False\nuse_803098 = False\nuse_401059_val = True\nuse_1977_train = False # 2024_0 + 2024_1 + 2020_1\nuse_1954_train = True # 2024_0 + 2024_1 + 2020_1\nuse_10999_train = False # 2024_0 + 2024_1 + 2020_1 + 2019_1\nuse_401059_train = False # 2024_0 + 2024_1\n\nclass CONFIG:\n    seed = 308\n    epochs = 8 if not is_debug else 2\n    \n    train_batch_size = 32\n    valid_batch_size = 512\n    img_size = [[160, 160],\n                [160, 160]]\n    now_cv = 0\n    n_classes = 1\n    n_folds = 5\n    \n    n_accumulate = 1.0\n    n_workers = os.cpu_count()\n    \n    formatted_time = None\n    ckpt_save_path = None\n\n    learning_rate = 1e-3 * train_batch_size * n_accumulate / 32\n    # learning_rate = 1e-5 * train_batch_size / 32 # eva02\n    total_sample = 1954\n    T_max = [1586 * epochs / train_batch_size // n_accumulate,\n             1522 * epochs / train_batch_size // n_accumulate,\n             1582 * epochs / train_batch_size // n_accumulate,\n             1574 * epochs / train_batch_size // n_accumulate,\n             1552 * epochs / train_batch_size // n_accumulate] # 401059\n    min_lr = 1e-6\n    weight_decay = 1e-6\n    scheduler = \"CosineAnnealingWithWarmupLR\" # 'CosineAnnealingLR'\n    DataParallel = False\n\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n    \"\"\"\n    tf_efficientnet_b0_ns\n    convnext_atto_ols.a2_in1k\n    tiny_vit_21m_512.dist_in22k_ft_in1k\n    eva02_base_patch14_224.mim_in22k\n    tf_efficientnetv2_s.in21k_ft_in1k\n    tf_efficientnetv2_l.in21k_ft_in1k\n    tf_efficientnetv2_b3.in21k_ft_in1k\n    tf_efficientnet_b3.ns_jft_in1k\n    convnextv2_tiny.fcmae_ft_in22k_in1k_384\n    convnext_tiny.fb_in22k_ft_in1k_384\n\n    efficientvit_b0.r224_in1k\n    efficientvit_b3.r256_in1k\n\n    edgenext_base.in21k_ft_in1k\n    eca_nfnet_l0.ra2_in1k\n    \"\"\"\n    model_name = \"ensemble_linear\"\n    model_names = [\"tf_efficientnetv2_s.in21k_ft_in1k\",\n                   \"edgenext_base.in21k_ft_in1k\",\n                   \"convnext_atto_ols.a2_in1k\",\n                   \"tf_efficientnet_b3.ns_jft_in1k\"]\n    ckpt_path = [\"/kaggle/input/20240827-efficientnetv2s-train1954-cv15496\",\n                 \"/kaggle/input/20240828-edgenext-train1954-cv0-1519\",\n                 \"/kaggle/input/20240829-convnext-atto-train1954-cv149\",\n                 \"/kaggle/input/20240829-efficientnet-b3-train1954-cv1504\"]\n    is_pretrained = False\n    backbone_grad = True\n    use_gempool = False\n    smooth_threshold = 0.05\n\n    old_my_train_csv = \"/kaggle/input/my-train-with-sgkfold/my_train_with_sgkfold.csv\"\n    my_train_csv = \"/kaggle/input/my-train-with-sgkfold/my_train_with_sgkfold.csv\"\n    train_img_dir = \"/kaggle/input/isic-2024-train-1954-imgs/train_1954_img\"\n    img_dir = \"/kaggle/input/isic-2024-challenge/train-image/image\"\n    \n    train_1954_csv = \"/kaggle/input/isic-2024-train-1954/train_1954.csv\"\n\nif CONFIG.DataParallel:\n    os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'\n    print(\"IN DataParallel!\")\nelse:\n    os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n    print(\"NO IN DataParallel!\")","metadata":{"execution":{"iopub.status.busy":"2024-09-08T06:18:40.643769Z","iopub.execute_input":"2024-09-08T06:18:40.644244Z","iopub.status.idle":"2024-09-08T06:18:40.692891Z","shell.execute_reply.started":"2024-09-08T06:18:40.644210Z","shell.execute_reply":"2024-09-08T06:18:40.691872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Set Random Seed","metadata":{}},{"cell_type":"code","source":"def set_seed(seed=308):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\nset_seed(CONFIG.seed)","metadata":{"execution":{"iopub.status.busy":"2024-09-08T06:18:40.693970Z","iopub.execute_input":"2024-09-08T06:18:40.694269Z","iopub.status.idle":"2024-09-08T06:18:40.713238Z","shell.execute_reply.started":"2024-09-08T06:18:40.694238Z","shell.execute_reply":"2024-09-08T06:18:40.712422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Progress","metadata":{}},{"cell_type":"code","source":"# root_dir = \"/kaggle/input/isic-2024-challenge/train-image/image\"\n# img_ids = os.listdir(root_dir)\n\n# min_size = 9999\n# max_size = 0\n# n_0_64 = 0\n# n_64_96 = 0\n# n_96_160 = 0\n# n_160_224 = 0\n# n_224_269 = 0\n# for img_id in tqdm(img_ids):\n#     path = os.path.join(root_dir, img_id)\n#     a = Image.open(path)\n#     s = np.array(a).shape[0]\n#     if s > max_size:\n#         max_size = s\n#     if s < min_size:\n#         min_size = s\n        \n#     if s >= 0 and s < 64:\n#         n_0_64 += 1\n#     elif s >= 64 and s < 96:\n#         n_64_96 += 1\n#     elif s >= 96 and s < 160:\n#         n_96_160 += 1\n#     elif s >= 160 and s < 224:\n#         n_160_224 += 1\n#     elif s >= 224:\n#         n_224_269 += 1\n        \n# print(f\"max_size : {max_size}\") # max_size : 269\n# print(f\"min_size : {min_size}\") # min_size : 41\n\n# print(f\"n_0_64    : {n_0_64}\")    # 86\n# print(f\"n_64_96   : {n_64_96}\")   # 3461\n# print(f\"n_96_160  : {n_96_160}\")  # 368914\n# print(f\"n_160_224 : {n_160_224}\") # 28305\n# print(f\"n_224_269 : {n_224_269}\") # 293\n\n# \"\"\"\n# The above code runs for : 37:20\n# \"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-09-08T06:18:40.715589Z","iopub.execute_input":"2024-09-08T06:18:40.716261Z","iopub.status.idle":"2024-09-08T06:18:40.721315Z","shell.execute_reply.started":"2024-09-08T06:18:40.716214Z","shell.execute_reply":"2024-09-08T06:18:40.720377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if os.path.exists(CONFIG.my_train_csv):\n    train = pd.read_csv(CONFIG.my_train_csv)\nelse:\n    train = pd.read_csv(CONFIG.train_csv)\n\nvalid = pd.read_csv(CONFIG.old_my_train_csv)\ntrain","metadata":{"execution":{"iopub.status.busy":"2024-09-08T06:18:40.722383Z","iopub.execute_input":"2024-09-08T06:18:40.722685Z","iopub.status.idle":"2024-09-08T06:18:51.840962Z","shell.execute_reply.started":"2024-09-08T06:18:40.722655Z","shell.execute_reply":"2024-09-08T06:18:51.840026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not os.path.exists(CONFIG.my_train_csv):\n    print(\"KFold....\")\n    # # Setting StratifiedKFold parameters\n    # skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=308)\n\n    # # Create a new column to hold the KFold labels\n    # train['kfold'] = -1\n\n    # # Iterate over each fold and assign labels\n    # for fold, (train_idx, val_idx) in enumerate(skf.split(train, train['target'])):\n    #     train.loc[val_idx, 'kfold'] = fold\ntrain","metadata":{"execution":{"iopub.status.busy":"2024-09-08T06:18:51.842240Z","iopub.execute_input":"2024-09-08T06:18:51.842579Z","iopub.status.idle":"2024-09-08T06:18:52.081657Z","shell.execute_reply.started":"2024-09-08T06:18:51.842544Z","shell.execute_reply":"2024-09-08T06:18:52.080683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if use_803098:\n    new_train = train\nelse:\n    if use_1954_train:\n        new_train = pd.read_csv(CONFIG.train_1954_csv)\n    elif use_1977_train:\n        new_train = pd.read_csv(CONFIG.train_1977_csv)\n    elif use_10999_train:\n        new_train = pd.read_csv(CONFIG.train_10999_csv)\n    elif use_401059_train:\n        new_train = pd.read_csv(CONFIG.my_train_csv)\n    else:\n        new_train = pd.read_csv(CONFIG.train_793_csv)\n    # train_0 = train[train[\"target\"] != 1] # 400666 rows × 56 columns\n    # train_1 = train[train[\"target\"] == 1] # 393 rows × 56 columns\n\n    # train_0 = train_0.reset_index(drop=True)\n    # train_1 = train_1.reset_index(drop=True)\n\n    # # train_1[train_1[\"kfold\"] == 4] # [78, 79, 79, 79, 78] sum --> 393\n\n    # # 0 : 1 ---> 1020 : 1\n\n    # # Each fold takes 80 samples, a total of 400\n    # some_train_0 = []\n    # for fold in range(CONFIG.n_folds):\n    #     _tmp = train_0[train_0[\"kfold\"] == fold].reset_index(drop=True).iloc[:200, :]\n    #     some_train_0.append(_tmp)\n\n    # some_train_0 = pd.concat(some_train_0).reset_index(drop=True)\n    # some_train_0\n\n    # new_train = pd.concat([some_train_0, train_1]).reset_index(drop=True)\n    # new_train = pd.concat([new_train, train_1_2020]).reset_index(drop=True)\n    # new_train = new_train.sample(frac=1).reset_index(drop=True)\nnew_train","metadata":{"execution":{"iopub.status.busy":"2024-09-08T06:18:52.082772Z","iopub.execute_input":"2024-09-08T06:18:52.083083Z","iopub.status.idle":"2024-09-08T06:18:52.144768Z","shell.execute_reply.started":"2024-09-08T06:18:52.083050Z","shell.execute_reply":"2024-09-08T06:18:52.143863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset and DataLoader","metadata":{}},{"cell_type":"code","source":"class HairAugmentation(A.ImageOnlyTransform):\n    def __init__(self, num_hairs_range=(5, 15), hair_color_range=((0, 0, 0), (255, 255, 255)), always_apply=False, p=0.5):\n        super(HairAugmentation, self).__init__(always_apply, p)\n        self.num_hairs_range = num_hairs_range\n        self.hair_color_range = hair_color_range\n\n    def apply(self, img, **params):\n        img = img.copy()\n        h, w, _ = img.shape\n\n        num_hairs = random.randint(self.num_hairs_range[0], self.num_hairs_range[1])\n        hair_color = (\n            random.randint(self.hair_color_range[0][0], self.hair_color_range[1][0]),\n            random.randint(self.hair_color_range[0][1], self.hair_color_range[1][1]),\n            random.randint(self.hair_color_range[0][2], self.hair_color_range[1][2])\n        )\n\n        for _ in range(num_hairs):\n            # Randomly choose the position and size of the hair\n            x1, y1 = random.randint(0, w), random.randint(0, h)\n            x2, y2 = random.randint(0, w), random.randint(0, h)\n            thickness = random.randint(1, 1)  # Making the hair thinner\n            img = cv2.line(img, (x1, y1), (x2, y2), hair_color, thickness)\n\n        return img\n\n    def get_params_dependent_on_targets(self, params):\n        return {}\n\n    def get_transform_init_args_names(self):\n        return (\"num_hairs_range\", \"hair_color_range\")\n    \n# HairAugmentation(num_hairs_range=(5, 15), hair_color_range=((0, 0, 0), (255, 255, 255)), p=1.0)","metadata":{"execution":{"iopub.status.busy":"2024-09-08T06:18:52.145849Z","iopub.execute_input":"2024-09-08T06:18:52.146145Z","iopub.status.idle":"2024-09-08T06:18:52.156510Z","shell.execute_reply.started":"2024-09-08T06:18:52.146089Z","shell.execute_reply":"2024-09-08T06:18:52.155704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def transform(img, img_size):\n    composition = A.Compose([\n        A.Resize(img_size[0], img_size[1]),\n        A.Normalize(),\n        ToTensorV2(),\n    ])\n    return composition(image=img)[\"image\"]","metadata":{"execution":{"iopub.status.busy":"2024-09-08T06:18:52.157696Z","iopub.execute_input":"2024-09-08T06:18:52.158143Z","iopub.status.idle":"2024-09-08T06:18:52.170041Z","shell.execute_reply.started":"2024-09-08T06:18:52.158079Z","shell.execute_reply":"2024-09-08T06:18:52.169155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class MyDataset(Dataset):\n#     def __init__(self, df, transform=None, mode=\"train\", threshold=CONFIG.smooth_threshold):\n#         super().__init__()\n#         self.df = df\n#         self.transform = transform\n#         self.mode = mode\n#         self.threshold = threshold\n\n#     def __len__(self):\n#         return len(self.df)\n    \n#     def __getitem__(self, idx):\n#         row = self.df.iloc[idx, :]\n#         img_id = row.isic_id + \".jpg\"\n#         label = torch.tensor(row.target, dtype=torch.float32)\n        \n#         if use_803098:\n#             if label.item() == 1:\n#                 img_path = os.path.join(CONFIG.new_train_img_dir, img_id)\n#             else:\n#                 img_path = os.path.join(CONFIG.train_img_dir, img_id)\n#         else:\n#             img_path = os.path.join(CONFIG.train_img_dir, img_id)\n#         img = Image.open(img_path)\n#         img = np.array(img)\n\n#         if self.transform != None:\n#             img = self.transform(img)\n        \n#         if self.mode == \"train\":\n#             if label == 0:\n#                 # label += (self.threshold / 2)\n#                 label += self.threshold\n#             elif label == 1:\n#                 # label -= (self.threshold / 2)\n#                 label -= self.threshold\n#             else:\n#                 raise(\"label is not 0 or 1\")\n#         elif self.mode == \"valid\":\n#             pass\n#         else:\n#             raise(\"mode is not train or valid\")\n\n#         return img, label\n\nclass MyDataset(Dataset):\n    def __init__(self, df, transform=None, n_models=None):\n        super().__init__()\n        self.df = df\n        self.transform = transform\n        self.n_models = n_models\n\n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx, :]\n        img_id = row.isic_id + \".jpg\"\n        label = torch.tensor(row.target, dtype=torch.float32)\n        \n        img_path = os.path.join(CONFIG.train_img_dir, img_id)\n        if os.path.exists(img_path) is False:\n            img_path = os.path.join(CONFIG.img_dir, img_id)\n        img = Image.open(img_path)\n        img = np.array(img)\n\n        if self.transform != None:\n            img = self.transform(img, img_size=CONFIG.img_size[self.n_models])\n\n        return img, label","metadata":{"execution":{"iopub.status.busy":"2024-09-08T06:18:52.173762Z","iopub.execute_input":"2024-09-08T06:18:52.174174Z","iopub.status.idle":"2024-09-08T06:18:52.184628Z","shell.execute_reply.started":"2024-09-08T06:18:52.174132Z","shell.execute_reply":"2024-09-08T06:18:52.183856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_loaders(df, fold=0, n_models=0):\n    df_train = df[df[\"kfold\"] != fold]\n    df_valid = valid[valid[\"kfold\"] == fold]\n    # if use_401059_val:\n    #     df_valid = valid[valid[\"kfold\"] == fold]\n    # else:\n    #     df_valid = df[df[\"kfold\"] == fold]\n    \n    # train_datasets = MyDataset(df=df_train, transform=transform_train, mode=\"train\")\n    # valid_datasets = MyDataset(df=df_valid, transform=transform_val, mode=\"valid\")\n    train_datasets = MyDataset(df=df_train, transform=transform, n_models=n_models)\n    valid_datasets = MyDataset(df=df_valid, transform=transform, n_models=n_models)\n    \n    train_loader = DataLoader(train_datasets, batch_size=CONFIG.train_batch_size, num_workers=CONFIG.n_workers, shuffle=True, pin_memory=True)\n    valid_loader = DataLoader(valid_datasets, batch_size=CONFIG.valid_batch_size, num_workers=CONFIG.n_workers, shuffle=False, pin_memory=True)\n    \n    \n    return train_loader, valid_loader","metadata":{"execution":{"iopub.status.busy":"2024-09-08T06:18:52.185844Z","iopub.execute_input":"2024-09-08T06:18:52.186392Z","iopub.status.idle":"2024-09-08T06:18:52.197911Z","shell.execute_reply.started":"2024-09-08T06:18:52.186348Z","shell.execute_reply":"2024-09-08T06:18:52.197059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_loader, valid_loader = prepare_loaders(train)\n# x, y = next(iter(train_loader))\n# x.shape\n# x, y = next(iter(valid_loader))\n# y","metadata":{"execution":{"iopub.status.busy":"2024-09-08T06:18:52.198950Z","iopub.execute_input":"2024-09-08T06:18:52.199275Z","iopub.status.idle":"2024-09-08T06:18:52.210683Z","shell.execute_reply.started":"2024-09-08T06:18:52.199243Z","shell.execute_reply":"2024-09-08T06:18:52.209767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluation","metadata":{}},{"cell_type":"code","source":"def compute_pAUC(y_true, y_scores, min_tpr=0.8):\n    y_hat = y_scores\n    if len(np.unique(y_true)) == 1:\n        return 0.0\n    min_tpr = min_tpr\n    max_fpr = abs(1 - min_tpr)\n    \n    v_gt = abs(y_true - 1)\n    v_pred = np.array([1.0 - x for x in y_hat])\n    \n    partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n    partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n    \n    return partial_auc\n\ny_true = np.array([0.0, 0.0, 1.0, 1.0])\ny_scores = np.array([0.0, 0.0, 0.9, 0.1])\n\npAUC = compute_pAUC(y_true, y_scores)\nprint(f\"pAUC: {pAUC:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-08T06:18:52.211966Z","iopub.execute_input":"2024-09-08T06:18:52.212264Z","iopub.status.idle":"2024-09-08T06:18:52.225797Z","shell.execute_reply.started":"2024-09-08T06:18:52.212233Z","shell.execute_reply":"2024-09-08T06:18:52.224961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## DL Model","metadata":{}},{"cell_type":"code","source":"def updata_req_grad(models, requires_grad=True):\n    for model in models:\n        for param in model.parameters():\n            param.requires_grad = requires_grad","metadata":{"execution":{"iopub.status.busy":"2024-09-08T06:18:52.226886Z","iopub.execute_input":"2024-09-08T06:18:52.227207Z","iopub.status.idle":"2024-09-08T06:18:52.234173Z","shell.execute_reply.started":"2024-09-08T06:18:52.227175Z","shell.execute_reply":"2024-09-08T06:18:52.233300Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class up2to4(nn.Module):\n    def __init__(self):\n        super(up2to4, self).__init__()\n        \n    def forward(self, x):\n        shape = x.shape\n        return x.reshape(shape[0], shape[1], 1, 1)\n\nclass GeMPool(nn.Module):\n    def __init__(self, p=3, eps=1e-6):\n        super(GeMPool, self).__init__()\n        self.p = nn.Parameter(torch.ones(1) * p)\n        self.eps = eps\n\n    def forward(self, x):\n        return self.gem(x, p=self.p, eps=self.eps)\n    \n    def gem(self, x, p=3, eps=1e-6):\n        return torch.mean(x.clamp(min=eps).pow(p), dim=(-2, -1)).pow(1./p)\n    \n    def __repr__(self):\n        return self.__class__.__name__ + f'(p={self.p.data.tolist()[0]:.4f}, eps={self.eps})'","metadata":{"execution":{"iopub.status.busy":"2024-09-08T06:18:52.235248Z","iopub.execute_input":"2024-09-08T06:18:52.235856Z","iopub.status.idle":"2024-09-08T06:18:52.246460Z","shell.execute_reply.started":"2024-09-08T06:18:52.235823Z","shell.execute_reply":"2024-09-08T06:18:52.245603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ensemblelinear(nn.Module):\n    def __init__(self, in_features, out_features=1) -> None:\n        super().__init__()\n        self.model = nn.Linear(in_features, in_features, bias=False)\n        self.softmax = nn.Softmax()\n        self.out_features = out_features\n\n    def forward(self, x):\n        Identity = x\n        _tmp = self.model(x)\n        _tmp = self.softmax(_tmp)\n        _tmp = Identity * _tmp\n        output = _tmp.sum(dim=1, keepdim=True)\n        return output","metadata":{"execution":{"iopub.status.busy":"2024-09-08T06:18:52.247570Z","iopub.execute_input":"2024-09-08T06:18:52.247921Z","iopub.status.idle":"2024-09-08T06:18:52.259246Z","shell.execute_reply.started":"2024-09-08T06:18:52.247876Z","shell.execute_reply":"2024-09-08T06:18:52.258426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ISIC2024Model(nn.Module):\n    def __init__(self, model_name=CONFIG.model_names[0]):\n        super(ISIC2024Model, self).__init__()\n        self.backbone = timm.create_model(model_name=model_name, \n                                          pretrained=False)\n        \n        if \"efficientnet\" in model_name:\n            in_features = self.backbone.classifier.in_features\n            self.backbone.classifier = nn.Identity()\n            if CONFIG.use_gempool:\n                self.backbone.global_pool = GeMPool()\n        elif \"convnext\" in model_name or \"tiny_vit\" in model_name:\n            in_features = self.backbone.head.fc.in_features\n            self.backbone.head.fc = nn.Identity()\n        elif \"eva\" in model_name:\n            in_features = 768\n        elif \"efficientvit\" in model_name:\n            in_features = self.backbone.head.classifier[4].in_features\n            self.backbone.head.classifier[4] = nn.Identity()\n        elif \"edgenext\" in model_name:\n            in_features = self.backbone.head.fc.in_features\n            self.backbone.head.fc = nn.Identity()\n\n        self.head = nn.Sequential(\n            nn.Linear(in_features, CONFIG.n_classes)\n        )\n        \n    def forward(self, x):\n        _tmp = self.backbone(x)\n        output = self.head(_tmp)\n        return output","metadata":{"execution":{"iopub.status.busy":"2024-09-08T06:18:52.260223Z","iopub.execute_input":"2024-09-08T06:18:52.260507Z","iopub.status.idle":"2024-09-08T06:18:52.270122Z","shell.execute_reply.started":"2024-09-08T06:18:52.260475Z","shell.execute_reply":"2024-09-08T06:18:52.269275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load DL Models","metadata":{}},{"cell_type":"code","source":"from collections import OrderedDict\n\ndef remove_module(path):\n    # 加载保存的状态字典\n    state_dict = torch.load(path)\n\n    # 使用 OrderedDict 去掉 'module.' 前缀\n    new_state_dict = OrderedDict()\n    for key, value in state_dict.items():\n        new_state_dict[key.replace('module.', '')] = value\n    return new_state_dict","metadata":{"execution":{"iopub.status.busy":"2024-09-08T06:18:52.271225Z","iopub.execute_input":"2024-09-08T06:18:52.271561Z","iopub.status.idle":"2024-09-08T06:18:52.282162Z","shell.execute_reply.started":"2024-09-08T06:18:52.271529Z","shell.execute_reply":"2024-09-08T06:18:52.281324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"more_models = []\n\nfor n_models in range(len(CONFIG.model_names)):\n    models = []\n    all_paths = sorted(os.listdir(CONFIG.ckpt_path[n_models]))\n    paths = []\n    for i in range(CONFIG.n_folds):\n        _tmp_paths = []\n        for path in all_paths:\n            if path[0] == str(i+1):\n                _tmp_paths.append(path)\n        paths.append(_tmp_paths[-1])\n    # paths = [\"1_CV0.1547_Loss0.6784_epoch2.bin\",\n    #          \"2_CV0.1708_Loss0.5088_epoch5.bin\",\n    #          \"3_CV0.1791_Loss0.3739_epoch7.bin\",\n    #          \"4_CV0.1654_Loss0.5382_epoch3.bin\",\n    #          \"5_CV0.1812_Loss0.4236_epoch8.bin\"]\n\n    if CONFIG.DataParallel:\n        device_ids = [0, 1]\n        for i in range(CONFIG.n_folds):\n            model = ISIC2024Model(model_name=CONFIG.model_names[n_models])\n            model = torch.nn.DataParallel(model, device_ids=device_ids)\n            model = model.cuda()\n            model.load_state_dict(torch.load(os.path.join(CONFIG.ckpt_path[n_models], paths[i])))\n            print(f\"fold : {i} --------- path : {paths[i]}\")\n            model.eval()\n            models.append(model)\n    else:\n        for i in range(CONFIG.n_folds):\n            model = ISIC2024Model(model_name=CONFIG.model_names[n_models])\n            model = model.cuda()\n            model.load_state_dict(remove_module(os.path.join(CONFIG.ckpt_path[n_models], paths[i])))\n            print(f\"fold : {i} --------- path : {paths[i]}\")\n            model.eval()\n            models.append(model)\n    more_models.append(models)\n    print(f\"{CONFIG.model_names[n_models]} load success.\")","metadata":{"execution":{"iopub.status.busy":"2024-09-08T06:18:52.283160Z","iopub.execute_input":"2024-09-08T06:18:52.283448Z","iopub.status.idle":"2024-09-08T06:19:08.999297Z","shell.execute_reply.started":"2024-09-08T06:18:52.283416Z","shell.execute_reply":"2024-09-08T06:19:08.998361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train and Valid Function","metadata":{}},{"cell_type":"code","source":"criterion = nn.BCELoss()\n\n\"\"\"\na = torch.tensor([0, 0, 1, 1]).float()\nb = torch.tensor([0.7, 0.2, 0.5, 0.3]).float()\nc = torch.tensor([[0.7], [0.2], [0.5], [0.3]]).float()\ncriterion(a, b)\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-09-08T06:19:09.000517Z","iopub.execute_input":"2024-09-08T06:19:09.000802Z","iopub.status.idle":"2024-09-08T06:19:09.006891Z","shell.execute_reply.started":"2024-09-08T06:19:09.000771Z","shell.execute_reply":"2024-09-08T06:19:09.006144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_one_epoch(model, dl_models, optimizer, scheduler, train_loader, epoch):\n    model.train()\n    \n    y_preds = []\n    y_trues = []\n    \n    dataset_size = 0\n    running_loss = 0.0\n    bar = tqdm(enumerate(train_loader), total=len(train_loader))\n    for step, (images, labels) in bar:\n        optimizer.zero_grad()\n        \n        batch_size = images.size(0)\n        if CONFIG.DataParallel:\n            images = images.cuda().float()\n            labels = labels.cuda().float()\n        else:\n            images = images.to(CONFIG.device, dtype=torch.float)\n            labels = labels.to(CONFIG.device, dtype=torch.float)\n            \n        ensemble_input = []\n        with torch.no_grad():\n            for dl_model in dl_models:\n                outputs = dl_model(images)\n                outputs = F.sigmoid(outputs)\n                ensemble_input.append(outputs)\n            ensemble_input = torch.cat(ensemble_input, axis=1)\n\n        outputs = model(ensemble_input)\n        loss = criterion(outputs.flatten(), labels) / CONFIG.n_accumulate\n        loss.backward()\n        \n        if (step + 1) % CONFIG.n_accumulate == 0:\n            optimizer.step()\n\n            # zero the parameter gradients\n            optimizer.zero_grad()\n\n            if scheduler is not None:\n                scheduler.step()\n        y_preds.append(outputs.flatten().detach().cpu().numpy())\n        y_trues.append(labels.detach().cpu().numpy())\n\n        train_cv = compute_pAUC(np.concatenate(y_trues).round(), np.concatenate(y_preds))\n\n        running_loss += (loss.item() * batch_size)\n\n        dataset_size += batch_size\n        \n        epoch_loss = running_loss / dataset_size\n        \n        bar.set_postfix(Epoch=epoch,\n                        Train_Loss=epoch_loss,\n                        Train_CV_pAUC=train_cv,\n                        LR=optimizer.param_groups[0]['lr'])\n    # Ensure that a parameter update is performed after the last accumulation cycle\n    if (step + 1) % CONFIG.n_accumulate != 0:\n        optimizer.step()\n        optimizer.zero_grad()\n        if scheduler is not None:\n                scheduler.step()\n        \n    return epoch_loss, train_cv","metadata":{"execution":{"iopub.status.busy":"2024-09-08T06:19:09.008018Z","iopub.execute_input":"2024-09-08T06:19:09.008396Z","iopub.status.idle":"2024-09-08T06:19:09.028101Z","shell.execute_reply.started":"2024-09-08T06:19:09.008355Z","shell.execute_reply":"2024-09-08T06:19:09.027146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@torch.inference_mode()\ndef valid_one_epoch(model, dl_models, optimizer, valid_loader, epoch):\n    model.eval()\n    \n    y_preds = []\n    y_trues = []\n    dataset_size = 0\n    running_loss = 0.0\n    bar = tqdm(enumerate(valid_loader), total=len(valid_loader))\n    with torch.no_grad():\n        for step, (images, labels) in bar:\n            batch_size = images.size(0)\n            if CONFIG.DataParallel:\n                images = images.cuda().float()\n                labels = labels.cuda().float()\n            else:\n                images = images.to(CONFIG.device, dtype=torch.float)\n                labels = labels.to(CONFIG.device, dtype=torch.float)\n\n            ensemble_input = []\n            for dl_model in dl_models:\n                outputs = dl_model(images)\n                outputs = F.sigmoid(outputs)\n                ensemble_input.append(outputs)\n            ensemble_input = torch.cat(ensemble_input, axis=1)\n\n            outputs = model(ensemble_input)\n            loss = criterion(outputs.flatten(), labels) / CONFIG.n_accumulate\n\n            y_preds.append(outputs.flatten().detach().cpu().numpy())\n            y_trues.append(labels.detach().cpu().numpy())\n            valid_cv = compute_pAUC(np.concatenate(y_trues), np.concatenate(y_preds))\n        \n            running_loss += (loss.item() * batch_size)\n\n            dataset_size += batch_size\n\n            epoch_loss = running_loss / dataset_size\n\n            bar.set_postfix(Epoch=epoch,\n                            Valid_Loss=epoch_loss,\n                            Valid_CV_pAUC=valid_cv,\n                            LR=optimizer.param_groups[0]['lr'])\n        \n\n        y_preds = np.concatenate(y_preds)\n        y_trues = np.concatenate(y_trues)\n        cv = compute_pAUC(y_trues, y_preds) \n    \n    return epoch_loss, cv","metadata":{"execution":{"iopub.status.busy":"2024-09-08T06:19:09.029434Z","iopub.execute_input":"2024-09-08T06:19:09.029750Z","iopub.status.idle":"2024-09-08T06:19:09.041695Z","shell.execute_reply.started":"2024-09-08T06:19:09.029716Z","shell.execute_reply":"2024-09-08T06:19:09.040904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the current time stamp\ncurrent_time = time.time()\nprint(\"Current timestamp:\", current_time)\n\n# Convert a timestamp to a local time structure\nlocal_time = time.localtime(current_time)\n\n# Formatting local time\nCONFIG.formatted_time = time.strftime('%Y-%m-%d_%H:%M:%S', local_time)\nprint(\"Current time:\", CONFIG.formatted_time)\n\nCONFIG.ckpt_save_path = f\"output/{CONFIG.formatted_time}_{CONFIG.model_name}_output\"\nif os.path.exists(CONFIG.ckpt_save_path) is False:\n    os.makedirs(CONFIG.ckpt_save_path)","metadata":{"execution":{"iopub.status.busy":"2024-09-08T06:19:09.042792Z","iopub.execute_input":"2024-09-08T06:19:09.043067Z","iopub.status.idle":"2024-09-08T06:19:09.056376Z","shell.execute_reply.started":"2024-09-08T06:19:09.043036Z","shell.execute_reply":"2024-09-08T06:19:09.055486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_training(fold, model, dl_models, optimizer, scheduler, train_loader, valid_loader, num_epochs=CONFIG.epochs, now_cv=CONFIG.now_cv):\n    if torch.cuda.is_available():\n        print(\"[INFO] Using GPU: {} x {}\\n\".format(torch.cuda.get_device_name(), torch.cuda.device_count()))\n    \n    start = time.time()\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_epoch_cv = now_cv\n    best_model_path = None\n    history = defaultdict(list)\n    \n    for epoch in range(1, num_epochs + 1):\n        gc.collect()\n        train_epoch_loss, train_epoch_cv = train_one_epoch(model, dl_models, optimizer, scheduler, train_loader, epoch)\n        valid_epoch_loss, valid_epoch_cv = valid_one_epoch(model, dl_models, optimizer, valid_loader, epoch)\n        print(f\"epoch: {epoch}, LOSS = {valid_epoch_loss}, CV = {valid_epoch_cv}\")\n        \n        history['Train Loss'].append(train_epoch_loss)\n        history['Valid Loss'].append(valid_epoch_loss)\n        history['Train CV'].append(train_epoch_cv)\n        history['Valid CV'].append(valid_epoch_cv)\n        history['lr'].append(scheduler.get_lr()[0])\n        \n        # deep copy the model\n        if valid_epoch_cv >= best_epoch_cv:\n            print(f\"{b_}epoch: {epoch}, Validation CV Improved ({best_epoch_cv} ---> {valid_epoch_cv}))\")\n            best_epoch_cv = valid_epoch_cv\n            best_model_wts = copy.deepcopy(model.state_dict())\n            PATH = \"./{}/{}_CV_{:.4f}_Loss{:.4f}_epoch{:.0f}.bin\".format(CONFIG.ckpt_save_path, fold, best_epoch_cv, valid_epoch_loss, epoch)\n            best_model_path = PATH\n            torch.save(model.state_dict(), PATH)\n            print(f\"Model Saved{sr_}\")\n            \n        print()\n    \n    end = time.time()\n    time_elapsed = end - start\n    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n    print(\"Best CV: {:.4f}\".format(best_epoch_cv))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n\n    return model, history, best_model_path","metadata":{"execution":{"iopub.status.busy":"2024-09-08T06:19:09.057455Z","iopub.execute_input":"2024-09-08T06:19:09.057758Z","iopub.status.idle":"2024-09-08T06:19:09.070528Z","shell.execute_reply.started":"2024-09-08T06:19:09.057725Z","shell.execute_reply":"2024-09-08T06:19:09.069629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Optimizer","metadata":{}},{"cell_type":"code","source":"class CosineAnnealingWithWarmupLR(_LRScheduler):\n    def __init__(self, optimizer, T_max, eta_min=0, warmup_epochs=10, last_epoch=-1):\n        self.T_max = T_max\n        self.eta_min = eta_min\n        self.warmup_epochs = warmup_epochs\n        self.cosine_epochs = T_max - warmup_epochs\n        super(CosineAnnealingWithWarmupLR, self).__init__(optimizer, last_epoch)\n\n    def get_lr(self):\n        if self.last_epoch < self.warmup_epochs:\n            # Linear warmup\n            return [(base_lr * (self.last_epoch + 1) / self.warmup_epochs) for base_lr in self.base_lrs]\n        else:\n            # Cosine annealing\n            cosine_epoch = self.last_epoch - self.warmup_epochs\n            return [self.eta_min + (base_lr - self.eta_min) * (1 + math.cos(math.pi * cosine_epoch / self.cosine_epochs)) / 2 for base_lr in self.base_lrs]\n","metadata":{"execution":{"iopub.status.busy":"2024-09-08T06:19:09.071645Z","iopub.execute_input":"2024-09-08T06:19:09.071947Z","iopub.status.idle":"2024-09-08T06:19:09.083015Z","shell.execute_reply.started":"2024-09-08T06:19:09.071915Z","shell.execute_reply":"2024-09-08T06:19:09.082163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The learning rate decreases with training\ndef fetch_scheduler(optimizer, T_max, min_lr):\n    if CONFIG.scheduler == 'CosineAnnealingLR':\n        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=T_max, \n                                                   eta_min=min_lr)\n    elif CONFIG.scheduler == \"CosineAnnealingWithWarmupLR\":\n        scheduler = CosineAnnealingWithWarmupLR(optimizer, T_max=T_max, eta_min=min_lr, warmup_epochs=T_max//CONFIG.train_batch_size)\n        \n    elif CONFIG.scheduler == None:\n        return None\n        \n    return scheduler","metadata":{"execution":{"iopub.status.busy":"2024-09-08T06:19:09.084011Z","iopub.execute_input":"2024-09-08T06:19:09.084348Z","iopub.status.idle":"2024-09-08T06:19:09.093075Z","shell.execute_reply.started":"2024-09-08T06:19:09.084316Z","shell.execute_reply":"2024-09-08T06:19:09.092165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# optimizer = torch.optim.AdamW(model.parameters(), lr=CONFIG.learning_rate, \n#                               weight_decay=CONFIG.weight_decay)\n# scheduler = fetch_scheduler(optimizer, T_max=CONFIG.T_max, min_lr=CONFIG.min_lr)","metadata":{"execution":{"iopub.status.busy":"2024-09-08T06:19:09.094213Z","iopub.execute_input":"2024-09-08T06:19:09.094774Z","iopub.status.idle":"2024-09-08T06:19:09.106012Z","shell.execute_reply.started":"2024-09-08T06:19:09.094731Z","shell.execute_reply":"2024-09-08T06:19:09.105053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Start Training","metadata":{}},{"cell_type":"code","source":"# Open the file and open it in write mode 'w' to write cfg information\nwith open(f'{CONFIG.ckpt_save_path}/info.txt', 'w') as file:\n    # Write a string to a file\n    if use_1954_train:\n        file.write(f'train on 1954\\n')\n    elif use_1977_train:\n        file.write(f'train on 1977\\n')\n    elif use_10999_train:\n        file.write(f'train on 10999\\n')\n    elif use_401059_train:\n        file.write(f'train on 401059\\n')\n    else:\n        file.write(f'train on 793\\n')\n\n    if use_401059_val:\n        file.write(f'valid on 401059\\n')\n        \n    file.write(f'seed: {CONFIG.seed}\\n')\n    file.write(f'epochs: {CONFIG.epochs}\\n')\n    file.write(f'train_batch_size: {CONFIG.train_batch_size}\\n')\n    file.write(f'valid_batch_size: {CONFIG.valid_batch_size}\\n')\n    file.write(f'img_size: {CONFIG.img_size}\\n')\n    file.write(f'n_classes: {CONFIG.n_classes}\\n')\n    file.write(f'n_folds: {CONFIG.n_folds}\\n')\n    file.write(f'learning_rate: {CONFIG.learning_rate}\\n')\n    file.write(f'model_name: {CONFIG.model_name}\\n')\n    file.write(f'use_gempool: {CONFIG.use_gempool}\\n')\n    file.write(f'smooth_threshold: {CONFIG.smooth_threshold}\\n')\n    file.write(f'model_names: {CONFIG.model_names}\\n')\n    file.write(f'ckpt_path: {CONFIG.ckpt_path}\\n')","metadata":{"execution":{"iopub.status.busy":"2024-09-08T06:19:09.111390Z","iopub.execute_input":"2024-09-08T06:19:09.111696Z","iopub.status.idle":"2024-09-08T06:19:09.120245Z","shell.execute_reply.started":"2024-09-08T06:19:09.111665Z","shell.execute_reply":"2024-09-08T06:19:09.119303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oof = []\ntrue = []\nhistorys = []\n\nfor fold in range(0, CONFIG.n_folds):\n    print(f\"==================== Train on Fold {fold+1} ====================\")\n    del model\n    torch.cuda.empty_cache()\n    model = ensemblelinear(in_features=len(CONFIG.model_names))\n    if CONFIG.DataParallel:\n        device_ids = [0, 1] # Two graphics cards with IDs 0 and 1\n        model = torch.nn.DataParallel(model, device_ids=device_ids)\n        model = model.cuda()\n    else:\n        model = model.to(CONFIG.device)\n    dl_models = []\n    for models in more_models:\n        dl_models.append(models[fold])\n        \n    optimizer = torch.optim.AdamW(model.parameters(), lr=CONFIG.learning_rate, \n                                  weight_decay=CONFIG.weight_decay)\n    scheduler = fetch_scheduler(optimizer, T_max=CONFIG.T_max[fold], min_lr=CONFIG.min_lr)\n    \n    train_loader, valid_loader = prepare_loaders(new_train, fold, 0)\n    model, history, best_model_path = run_training(fold+1, model, dl_models, optimizer, scheduler, \n                                                   train_loader, valid_loader, \n                                                   num_epochs=CONFIG.epochs, now_cv=CONFIG.now_cv)\n    historys.append(history)\n    \n    bar = tqdm(enumerate(valid_loader), total=len(valid_loader))\n    with torch.no_grad():\n        for step, (images, labels) in bar:\n            batch_size = images.size(0)\n            if CONFIG.DataParallel:\n                images = images.cuda().float()\n                labels = labels.cuda().float()\n            else:\n                images = images.to(CONFIG.device, dtype=torch.float)\n                labels = labels.to(CONFIG.device, dtype=torch.float)\n\n            ensemble_input = []\n            for dl_model in dl_models:\n                outputs = dl_model(images)\n                outputs = F.sigmoid(outputs)\n                ensemble_input.append(outputs)\n            ensemble_input = torch.cat(ensemble_input, axis=1)\n\n            outputs = model(ensemble_input)\n\n            oof.append(outputs.flatten().detach().cpu().numpy())\n            true.append(labels.detach().cpu().numpy())\n        print()\n\noof = np.concatenate(oof)\ntrue = np.concatenate(true)","metadata":{"execution":{"iopub.status.busy":"2024-09-08T06:19:09.121627Z","iopub.execute_input":"2024-09-08T06:19:09.121994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Local CV","metadata":{}},{"cell_type":"code","source":"local_cv = compute_pAUC(true, oof)\nprint(\"Local CV : \", local_cv)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# np.save(f\"result_analysis/{CONFIG.formatted_time}_{CONFIG.model_name}.npy\", oof)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Open the file in append mode 'a'\nwith open(f'{CONFIG.ckpt_save_path}/info.txt', 'a') as file:\n    # Append a string to a file\n    file.write(f'cv: {local_cv}\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Logs","metadata":{}},{"cell_type":"code","source":"fold = 0\nhistory = historys[fold]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot( range(len(history[\"Train Loss\"])), history[\"Train Loss\"], label=\"Train Loss\")\nplt.plot( range(len(history[\"Valid Loss\"])), history[\"Valid Loss\"], label=\"Valid Loss\")\nplt.xlabel(\"epochs\")\nplt.ylabel(\"Loss\")\nplt.grid()\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot( range(len(history[\"Train CV\"])), history[\"Train CV\"], label=\"Train CV\")\nplt.plot( range(len(history[\"Valid CV\"])), history[\"Valid CV\"], label=\"Valid CV\")\nplt.xlabel(\"epochs\")\nplt.ylabel(\"CV or AUC\")\nplt.grid()\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot( range(len(history[\"lr\"])), history[\"lr\"], label=\"lr\")\nplt.xlabel(\"epochs\")\nplt.ylabel(\"lr\")\nplt.grid()\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}